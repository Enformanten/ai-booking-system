{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Thermo Booking recommender system for energy optimization for the GovTech Smart M 2 OPI project. Background The purpose of the OPI project is to achieve savings on energy and climate consumption by consolidating activities, implementing intelligent local allocation, and increasing the utilization rate of the municipal building stock through the use of building data, IoT solutions (Internet of Things), and artificial intelligence (AI). The municipalities wish to carry out a public-private innovation collaboration with NTT DATA, in which the municipalities, together with NTT DATA, investigate, test, and specify which components and processes are necessary, regardless of the choice of supplier, for a later solution in a nationwide tender, which focuses on providing insight and overview of energy consumption at the three selected primary schools, and to develop the solution as an AI solution for optimizing energy consumption outside of normal school hours, from 4pm to 10pm on weekdays and during the weekends. Daytime hours are not included in local optimization as it is not possible to extract data from AULA, and because it would exceed the project's economic framework to rely on a solution that can retrieve data from AULA through alternative means. Project objectives To provide users with an overview of possible bookings for a given building, ranked by estimated energy optimality. To use existing data sources to estimate the energy cost associated with possible bookings, including: Building plan (room location relative to other rooms) Room capacity and inherent functionalities (whiteboard, kitchen equipment, etc.) Indoor climate Energy consumption To identify the necessary data sources to build this type of AI solution. Users Building managers (professionals responsible for booking rooms on behalf of leisure users and/or monitoring and controlling CTS operation). Leisure users (third-party users who want to book a room in the given building). Use case (What actions should be possible via the AI solution?) (In the following, it is assumed that the AI solution is connected to a web-based application with a GUI) - Retrieve/see a ranked list of estimated climate-optimal bookings for a given building at the given time. Demo GUI A GUI (built in streamlit) is available @ https://app-govtech-demo.azurewebsites.net/ NOTE : May be taken down during/after the project. Example usage (Installation guide is excluded from this public documentation.) Building specifications are loaded from a config directory, through the .from_config method. The booking state is retrieved under the hood through an open API. from thermo.recommender import Recommender from datetime import date recommender = Recommender . from_config ( building_name = \"demo_school\" ) recommendation = recommender . run ( day = date . today ()) recommendation . show () show() returns a color-coded DataFrame.Styler object, similar to the following table Room A ... Room G Room H Room I t_0 1.0 ... 1.0 1.0 0.5 t_1 1.0 ... 1.0 0.5 t_2 1.0 ... 1.0 1.0 0.0 t_3 1.0 ... 1.0 0.5 t_4 1.0 ... 1.0 1.0 0.5 t_5 0.5 ... 0.5 1.0 1.0 t_6 ... 0.5 1.0 t_7 0.0 ... 1.0 1.0 With the empty cells representing time slots that are either already booked or infeasible due to the booking requirements (e.g., required capacity or particular amenities such as a whiteboard) Similarly, recommendation.top_recommendations() produces a list of room-time combinations, i.e. booking recommendations, ranked after their aggregated (estimated) cost ( score ). Time Slot Room Score t_2 Room I 0.0 t_7 Room E 0.0 t_0 Room I 0.5 t_1 Room H 0.5 t_3 Room H 0.5 ... ... ... t_7 Room F 1.0 User arguments User arguments (i.e. booking requirements) are passed to the .run function of the Recommender . recommendation = recommender . run ( recommender = recommender , day = date . today (), required_amenities = REQUIRED_AMENITIES , ... required_capacity = REQUIRED_CAPACITY , )","title":"Introduction"},{"location":"#thermo","text":"Booking recommender system for energy optimization for the GovTech Smart M 2 OPI project.","title":"Thermo"},{"location":"#background","text":"The purpose of the OPI project is to achieve savings on energy and climate consumption by consolidating activities, implementing intelligent local allocation, and increasing the utilization rate of the municipal building stock through the use of building data, IoT solutions (Internet of Things), and artificial intelligence (AI). The municipalities wish to carry out a public-private innovation collaboration with NTT DATA, in which the municipalities, together with NTT DATA, investigate, test, and specify which components and processes are necessary, regardless of the choice of supplier, for a later solution in a nationwide tender, which focuses on providing insight and overview of energy consumption at the three selected primary schools, and to develop the solution as an AI solution for optimizing energy consumption outside of normal school hours, from 4pm to 10pm on weekdays and during the weekends. Daytime hours are not included in local optimization as it is not possible to extract data from AULA, and because it would exceed the project's economic framework to rely on a solution that can retrieve data from AULA through alternative means.","title":"Background"},{"location":"#project-objectives","text":"To provide users with an overview of possible bookings for a given building, ranked by estimated energy optimality. To use existing data sources to estimate the energy cost associated with possible bookings, including: Building plan (room location relative to other rooms) Room capacity and inherent functionalities (whiteboard, kitchen equipment, etc.) Indoor climate Energy consumption To identify the necessary data sources to build this type of AI solution.","title":"Project objectives"},{"location":"#users","text":"Building managers (professionals responsible for booking rooms on behalf of leisure users and/or monitoring and controlling CTS operation). Leisure users (third-party users who want to book a room in the given building).","title":"Users"},{"location":"#use-case","text":"(What actions should be possible via the AI solution?) (In the following, it is assumed that the AI solution is connected to a web-based application with a GUI) - Retrieve/see a ranked list of estimated climate-optimal bookings for a given building at the given time.","title":"Use case"},{"location":"#demo-gui","text":"A GUI (built in streamlit) is available @ https://app-govtech-demo.azurewebsites.net/ NOTE : May be taken down during/after the project.","title":"Demo GUI"},{"location":"#example-usage","text":"(Installation guide is excluded from this public documentation.) Building specifications are loaded from a config directory, through the .from_config method. The booking state is retrieved under the hood through an open API. from thermo.recommender import Recommender from datetime import date recommender = Recommender . from_config ( building_name = \"demo_school\" ) recommendation = recommender . run ( day = date . today ()) recommendation . show () show() returns a color-coded DataFrame.Styler object, similar to the following table Room A ... Room G Room H Room I t_0 1.0 ... 1.0 1.0 0.5 t_1 1.0 ... 1.0 0.5 t_2 1.0 ... 1.0 1.0 0.0 t_3 1.0 ... 1.0 0.5 t_4 1.0 ... 1.0 1.0 0.5 t_5 0.5 ... 0.5 1.0 1.0 t_6 ... 0.5 1.0 t_7 0.0 ... 1.0 1.0 With the empty cells representing time slots that are either already booked or infeasible due to the booking requirements (e.g., required capacity or particular amenities such as a whiteboard) Similarly, recommendation.top_recommendations() produces a list of room-time combinations, i.e. booking recommendations, ranked after their aggregated (estimated) cost ( score ). Time Slot Room Score t_2 Room I 0.0 t_7 Room E 0.0 t_0 Room I 0.5 t_1 Room H 0.5 t_3 Room H 0.5 ... ... ... t_7 Room F 1.0","title":"Example usage"},{"location":"#user-arguments","text":"User arguments (i.e. booking requirements) are passed to the .run function of the Recommender . recommendation = recommender . run ( recommender = recommender , day = date . today (), required_amenities = REQUIRED_AMENITIES , ... required_capacity = REQUIRED_CAPACITY , )","title":"User arguments"},{"location":"capacity/","text":"Model for capacity Sprint 4 - AI version 2 Lets consider the problem with the capacity of the room. On the one hand side, it does not make sense to suggest the user a room that is too small for the planned activity: if the participants will not fit in the room, it does not matter if the energy required to heat it and light it is very low. On the other hand side, we want to avoid recommending rooms that are far too big (see below for how we approach defining way too big) for the activity planned: First, because it might result on heating a very big room to have two people in it, but most importantly, because the room could be better booked later by a larger group. Mathematical model We approach the problem as finding a cost for mismatched capacity that can be added to the other energy costs, that is, the electricity and the heating cost. We define the cost function \\(C_c\\) for a required capacity (i.e. the number of participants in the activity) \\(x\\) as for the \\(i\\) -th room as: \\[ C_c(x) = \\begin{cases} \\infty & \\text{if } x < c_i, \\\\ \\alpha \\frac{x-c_i}{c_i} & x \\leq c_i. \\end{cases} \\] where \\(c_i\\) is the capacity (i.e. the amount of people that fit) in room \\(i\\) and \\(\\alpha\\) is a coefficient that can be adjusted for business purposes for each school. Intuitively, this means that its not possible to book the room if \\(x < c_i\\) , since the participants will not fit, it is ''for free'' to book it if \\(x=c_i\\) , since the participants match the capacity, and if there is free space, there is an additional cost of \\(\\alpha/c_i\\) for each free spot in the room. The factor \\(1/c_i\\) in the expression for the cost models the relative importance of having an extra free sit: while having 5 free spots in a room with capacity for 10 people is having half of the sits empty and is not desirable, having 5 free spots in a room with capacity for 100 people is not a big problem. The first will be punished with an extra \\(0.5\\alpha\\) cost while the second example will be punished with the much smaller \\(0.05\\alpha\\) cost.","title":"Model for capacity"},{"location":"capacity/#model-for-capacity","text":"Sprint 4 - AI version 2 Lets consider the problem with the capacity of the room. On the one hand side, it does not make sense to suggest the user a room that is too small for the planned activity: if the participants will not fit in the room, it does not matter if the energy required to heat it and light it is very low. On the other hand side, we want to avoid recommending rooms that are far too big (see below for how we approach defining way too big) for the activity planned: First, because it might result on heating a very big room to have two people in it, but most importantly, because the room could be better booked later by a larger group.","title":"Model for capacity"},{"location":"capacity/#mathematical-model","text":"We approach the problem as finding a cost for mismatched capacity that can be added to the other energy costs, that is, the electricity and the heating cost. We define the cost function \\(C_c\\) for a required capacity (i.e. the number of participants in the activity) \\(x\\) as for the \\(i\\) -th room as: \\[ C_c(x) = \\begin{cases} \\infty & \\text{if } x < c_i, \\\\ \\alpha \\frac{x-c_i}{c_i} & x \\leq c_i. \\end{cases} \\] where \\(c_i\\) is the capacity (i.e. the amount of people that fit) in room \\(i\\) and \\(\\alpha\\) is a coefficient that can be adjusted for business purposes for each school. Intuitively, this means that its not possible to book the room if \\(x < c_i\\) , since the participants will not fit, it is ''for free'' to book it if \\(x=c_i\\) , since the participants match the capacity, and if there is free space, there is an additional cost of \\(\\alpha/c_i\\) for each free spot in the room. The factor \\(1/c_i\\) in the expression for the cost models the relative importance of having an extra free sit: while having 5 free spots in a room with capacity for 10 people is having half of the sits empty and is not desirable, having 5 free spots in a room with capacity for 100 people is not a big problem. The first will be punished with an extra \\(0.5\\alpha\\) cost while the second example will be punished with the much smaller \\(0.05\\alpha\\) cost.","title":"Mathematical model"},{"location":"graph/","text":"School as a graph Sprint 3 - AI version 1 Let every school be represented by one or more graphs, where each node represents a room in the school. In this representation, two rooms share an edge if they share a wall (or a floor-ceiling in case of the school having more than one floor). In this version, we represent the school as an undirected and unweighted graph, \\(G_s\\) . If the graph can be split into several subgraphs, we choose this representation. From here on we assume, for the sake of clarity, that the school is represented by a single, indivisible graph, but the discussion may be extended to multiple graphs in later versions. Let \\(N_r\\) be the number of rooms in the school and let \\(i=0, 1, ..., N_r-1\\) denote the \\(i\\) -th room of the school. Then, the adjacency matrix \\(A_s\\) of the school is given by: \\[ \\left( A_s\\right)_{ij} = \\begin{cases} 1 & \\text{if } i \\text{ and } j \\text{ share a wall}, \\\\ 0 & \\text{otherwise}. \\end{cases} \\] The booking system as a graph We also represent the booking system as a graph \\(G\\) , with \\(N_r \\times N_t\\) nodes, where \\(N_t\\) is the number of time slots for a day. The graph \\(G\\) consists of \\(N_t\\) copies of the graph \\(G_s\\) , where each copy represents the rooms of the school at a given time slot. Each room is connected to the rooms it shares a wall with, plus to the version of itself in the graphs representing the time-slots that take place immediately before and immediately after. The adjacency matrix for graph \\(G\\) , \\(A\\) , is a squared matrix of size \\(N_t N_r \\times N_t N_r\\) that can be built in block form as follows: \\[ A = \\left(\\begin{matrix} A_s & \\lambda\\mathbb{I} & \\mathbb{O} &\\cdots & \\mathbb{O} \\\\ \\lambda\\mathbb{I} & A_s & \\lambda\\mathbb{I} & \\cdots & \\mathbb{O} \\\\ \\mathbb{O} & \\lambda\\mathbb{I} & A_s & \\cdots & \\mathbb{O} \\\\ \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\ \\mathbb{O} & \\mathbb{O} & \\mathbb{O} &\\cdots & A_s\\\\ \\end{matrix} \\right), \\] where all blocks are of size \\(N_r \\times N_r\\) , \\(\\mathbb{I}\\) is the identity matrix , \\(\\mathbb{O}\\) is the null matrix and and \\(\\lambda\\) is a scalar coefficient representing the relative importance of time respect to space (more about this in the next section). Graph-based first-order model for the cost of heating rooms: Let us discuss how to compute the cost of heating a new room given some rooms have already been booked. Qualitative discussion: As a first order approximation, we can consider that the cost of heating a given room is the cost of heating that room if it was the only room used that day, minus the energy savings coming from other rooms that have already been booked. We assume those energy savings come from three sources: * Heating a room that shares a wall in the same time slot with a room that is already in use, * The room is already warm because it has been used in the previous time slot, * If this room is booked, it will already be warm when used in the next time slot. Intuitively we can think of this model as each room as having an intrinsic cost and then receiving messages from its nearest neighbors in graph \\(G\\) telling it to reduce its cost if they are already booked. The optimal rooms to book will be those that receive the most (or the most important) messages, thus, having the lowest cost. The parameter \\(\\lambda\\) in the definition of \\(G\\) controls the relative importance of the messages: - if \\(\\lambda > 1\\) , booking the same room over time is favored over booking adjacent rooms - if \\(\\lambda < 1\\) , booking adjacent rooms is favored over booking the same room at subsequent time slots - and if \\(\\lambda = 1\\) , the space and time components are treated on equal footing. The following section discusses a way of formalizing and implementing this model. Mathematical formulation of the model Let \\(s\\) be the schedule vector, of size \\(N_r N_t\\) , such that \\[ s_i = \\begin{cases} 1 & \\text{if room } (i \\mod N_r) \\text{ room is booked} \\\\ & \\text{at time } (i \\div N_t), \\\\ 0 & \\text{otherwise}; \\end{cases} \\] where \\(\\div\\) represents the integer division and $ \\cdot\\mod{\\cdot}$ represents its reminder. Equipped with this notation, we can write the first-order approximation of the cost as follows: \\[ c = c_a - \\eta As, \\] where \\(c\\) is the cost vector representing the cost of heating the room, \\(c_a\\) is a vector representing the cost of heating the room if this room at this time slot was the only room booked that day, and \\(\\eta\\) is a scalar coefficient representing the relative importance of the messages \\(As\\) compared to the alone costs \\(c_a\\) . Example: Let the school have 4 rooms, whose connectivity is given by the following spatial adjacency matrix: \\[ A_s = \\left(\\begin{matrix} 0 & 1 & 1 & 0 \\\\ 1 & 0 & 0 & 1 \\\\ 1 & 0 & 0 & 1 \\\\ 0 & 1 & 1 & 0 \\end{matrix} \\right). \\] The identity matrix for 4 rooms is given by: \\[ \\mathbb{I} = \\left(\\begin{matrix} 1 & 0 & 0 & 0 \\\\ 0 & 1 & 0 & 0 \\\\ 0 & 0 & 1 & 0 \\\\ 0 & 0 & 0 & 1 \\end{matrix} \\right) \\] and the null matrix by: \\[ \\mathbb{O} = \\left(\\begin{matrix} 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 \\end{matrix} \\right). \\] Lets assume we have three time slots for the day in question, \\(t=-1,0,1\\) . The adjacency matrix \\(A\\) for the booking graph \\(G\\) looks like: \\[ A = \\left(\\begin{matrix} A_s & \\lambda\\mathbb{I} & \\mathbb{O} \\\\ \\lambda\\mathbb{I} & A_s & \\lambda\\mathbb{I} \\\\ \\mathbb{O} & \\lambda\\mathbb{I} & A_s \\\\ \\end{matrix} \\right). \\] Lets say that the 0-th room was booked at time 0. Then, the schedule vector s looks like: \\[ s = \\left(\\begin{matrix} 0 & 0 & 0 & 0 \\\\ 1 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 \\\\ \\end{matrix} \\right), \\] where, \\(s\\) has been displayed in a rooms \\(\\times\\) time_slots format for convenience, but please keep in mind that it is a 1-D vector. The messages \\(As\\) look like: \\[ As = \\left(\\begin{matrix} \\lambda & 0 & 0 & 0 \\\\ 0 & 1 & 1 & 0 \\\\ \\lambda & 0 & 0 & 0 \\\\ \\end{matrix} \\right), \\] and, if we assume that all rooms where equally costly to heat alone, that is, \\(c_a = k (1,1,\\dots,1)\\) , then the cost of new possible bookings is: \\[ c = \\left(\\begin{matrix} k-\\eta\\lambda & k & k & k \\\\ k & k-\\eta & k-\\eta & k \\\\ k-\\eta\\lambda & k & k & k \\\\ \\end{matrix} \\right), \\] where \\(k\\) , \\(\\eta\\) and \\(\\lambda\\) are positive numbers. Note that the room that is already booked doesn't have an outstandingly high cost to be re-booked, this is to be corrected in subsequent versions of the model. If \\(\\lambda > 1\\) , the model suggest that the optimal room to book is the 0-th room at time slots \\(-1\\) or \\(1\\) , while if its smaller than 1, then its rooms 1 and 2 at time 0 that are optimal for booking.","title":"School as a graph"},{"location":"graph/#school-as-a-graph","text":"Sprint 3 - AI version 1 Let every school be represented by one or more graphs, where each node represents a room in the school. In this representation, two rooms share an edge if they share a wall (or a floor-ceiling in case of the school having more than one floor). In this version, we represent the school as an undirected and unweighted graph, \\(G_s\\) . If the graph can be split into several subgraphs, we choose this representation. From here on we assume, for the sake of clarity, that the school is represented by a single, indivisible graph, but the discussion may be extended to multiple graphs in later versions. Let \\(N_r\\) be the number of rooms in the school and let \\(i=0, 1, ..., N_r-1\\) denote the \\(i\\) -th room of the school. Then, the adjacency matrix \\(A_s\\) of the school is given by: \\[ \\left( A_s\\right)_{ij} = \\begin{cases} 1 & \\text{if } i \\text{ and } j \\text{ share a wall}, \\\\ 0 & \\text{otherwise}. \\end{cases} \\]","title":"School as a graph"},{"location":"graph/#the-booking-system-as-a-graph","text":"We also represent the booking system as a graph \\(G\\) , with \\(N_r \\times N_t\\) nodes, where \\(N_t\\) is the number of time slots for a day. The graph \\(G\\) consists of \\(N_t\\) copies of the graph \\(G_s\\) , where each copy represents the rooms of the school at a given time slot. Each room is connected to the rooms it shares a wall with, plus to the version of itself in the graphs representing the time-slots that take place immediately before and immediately after. The adjacency matrix for graph \\(G\\) , \\(A\\) , is a squared matrix of size \\(N_t N_r \\times N_t N_r\\) that can be built in block form as follows: \\[ A = \\left(\\begin{matrix} A_s & \\lambda\\mathbb{I} & \\mathbb{O} &\\cdots & \\mathbb{O} \\\\ \\lambda\\mathbb{I} & A_s & \\lambda\\mathbb{I} & \\cdots & \\mathbb{O} \\\\ \\mathbb{O} & \\lambda\\mathbb{I} & A_s & \\cdots & \\mathbb{O} \\\\ \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\ \\mathbb{O} & \\mathbb{O} & \\mathbb{O} &\\cdots & A_s\\\\ \\end{matrix} \\right), \\] where all blocks are of size \\(N_r \\times N_r\\) , \\(\\mathbb{I}\\) is the identity matrix , \\(\\mathbb{O}\\) is the null matrix and and \\(\\lambda\\) is a scalar coefficient representing the relative importance of time respect to space (more about this in the next section).","title":"The booking system as a graph"},{"location":"graph/#graph-based-first-order-model-for-the-cost-of-heating-rooms","text":"Let us discuss how to compute the cost of heating a new room given some rooms have already been booked.","title":"Graph-based first-order model for the cost of heating rooms:"},{"location":"graph/#qualitative-discussion","text":"As a first order approximation, we can consider that the cost of heating a given room is the cost of heating that room if it was the only room used that day, minus the energy savings coming from other rooms that have already been booked. We assume those energy savings come from three sources: * Heating a room that shares a wall in the same time slot with a room that is already in use, * The room is already warm because it has been used in the previous time slot, * If this room is booked, it will already be warm when used in the next time slot. Intuitively we can think of this model as each room as having an intrinsic cost and then receiving messages from its nearest neighbors in graph \\(G\\) telling it to reduce its cost if they are already booked. The optimal rooms to book will be those that receive the most (or the most important) messages, thus, having the lowest cost. The parameter \\(\\lambda\\) in the definition of \\(G\\) controls the relative importance of the messages: - if \\(\\lambda > 1\\) , booking the same room over time is favored over booking adjacent rooms - if \\(\\lambda < 1\\) , booking adjacent rooms is favored over booking the same room at subsequent time slots - and if \\(\\lambda = 1\\) , the space and time components are treated on equal footing. The following section discusses a way of formalizing and implementing this model.","title":"Qualitative discussion:"},{"location":"graph/#mathematical-formulation-of-the-model","text":"Let \\(s\\) be the schedule vector, of size \\(N_r N_t\\) , such that \\[ s_i = \\begin{cases} 1 & \\text{if room } (i \\mod N_r) \\text{ room is booked} \\\\ & \\text{at time } (i \\div N_t), \\\\ 0 & \\text{otherwise}; \\end{cases} \\] where \\(\\div\\) represents the integer division and $ \\cdot\\mod{\\cdot}$ represents its reminder. Equipped with this notation, we can write the first-order approximation of the cost as follows: \\[ c = c_a - \\eta As, \\] where \\(c\\) is the cost vector representing the cost of heating the room, \\(c_a\\) is a vector representing the cost of heating the room if this room at this time slot was the only room booked that day, and \\(\\eta\\) is a scalar coefficient representing the relative importance of the messages \\(As\\) compared to the alone costs \\(c_a\\) .","title":"Mathematical formulation of the model"},{"location":"graph/#example","text":"Let the school have 4 rooms, whose connectivity is given by the following spatial adjacency matrix: \\[ A_s = \\left(\\begin{matrix} 0 & 1 & 1 & 0 \\\\ 1 & 0 & 0 & 1 \\\\ 1 & 0 & 0 & 1 \\\\ 0 & 1 & 1 & 0 \\end{matrix} \\right). \\] The identity matrix for 4 rooms is given by: \\[ \\mathbb{I} = \\left(\\begin{matrix} 1 & 0 & 0 & 0 \\\\ 0 & 1 & 0 & 0 \\\\ 0 & 0 & 1 & 0 \\\\ 0 & 0 & 0 & 1 \\end{matrix} \\right) \\] and the null matrix by: \\[ \\mathbb{O} = \\left(\\begin{matrix} 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 \\end{matrix} \\right). \\] Lets assume we have three time slots for the day in question, \\(t=-1,0,1\\) . The adjacency matrix \\(A\\) for the booking graph \\(G\\) looks like: \\[ A = \\left(\\begin{matrix} A_s & \\lambda\\mathbb{I} & \\mathbb{O} \\\\ \\lambda\\mathbb{I} & A_s & \\lambda\\mathbb{I} \\\\ \\mathbb{O} & \\lambda\\mathbb{I} & A_s \\\\ \\end{matrix} \\right). \\] Lets say that the 0-th room was booked at time 0. Then, the schedule vector s looks like: \\[ s = \\left(\\begin{matrix} 0 & 0 & 0 & 0 \\\\ 1 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 \\\\ \\end{matrix} \\right), \\] where, \\(s\\) has been displayed in a rooms \\(\\times\\) time_slots format for convenience, but please keep in mind that it is a 1-D vector. The messages \\(As\\) look like: \\[ As = \\left(\\begin{matrix} \\lambda & 0 & 0 & 0 \\\\ 0 & 1 & 1 & 0 \\\\ \\lambda & 0 & 0 & 0 \\\\ \\end{matrix} \\right), \\] and, if we assume that all rooms where equally costly to heat alone, that is, \\(c_a = k (1,1,\\dots,1)\\) , then the cost of new possible bookings is: \\[ c = \\left(\\begin{matrix} k-\\eta\\lambda & k & k & k \\\\ k & k-\\eta & k-\\eta & k \\\\ k-\\eta\\lambda & k & k & k \\\\ \\end{matrix} \\right), \\] where \\(k\\) , \\(\\eta\\) and \\(\\lambda\\) are positive numbers. Note that the room that is already booked doesn't have an outstandingly high cost to be re-booked, this is to be corrected in subsequent versions of the model. If \\(\\lambda > 1\\) , the model suggest that the optimal room to book is the 0-th room at time slots \\(-1\\) or \\(1\\) , while if its smaller than 1, then its rooms 1 and 2 at time 0 that are optimal for booking.","title":"Example:"},{"location":"thermo/","text":"Thermal diffusivity We use a thermal diffusion model to simulate the heat transfer between rooms and to the outside of a school. We assume that the school and its internal walls are well insulated compared to the thermal conductivity of air, this is, we assume that the temperature in a room is almost constant with respect to the position inside it. We know there will be radiation effects (this is, rooms facing south will be warmer than rooms facing north when the heating is off) but we haven't taken them into account. We know there will be convection effects (this is, heat losses due to air currents), both from humans opening and closing the windows (but this we will never be able to model, at least not without extra information) and from the compulsory ventilation of the building. We haven't included a convection term, since it would make the simulation quite challenging, and we hope that the thermal loss due to built-in ventilation can be assimilated to diffusion losses through walls. We assume the school has some sort of automation built in for the heaters, so that they are able to turn on when there is a lecture and turn off when the room is not being used. Note we haven't done a full study of how a proper controller would work, since we haven't considered retrofitting effects into the controller. We have not considered other sources of heat, such as the people in the room, the light bulbs for illumination or the computers. Thus, we assume that the room is relatively \"large\" compared to the number of people \"crammed\" in. We can come back to this later, since it may have some impact in the optimization. These considerations result in a linear inhomogeneous system of ordinary differential equations. Even though we know it would be possible to transform the problem to the Laplace space to get a system of linear algebraic equations instead and then transform back, making the module less computationally expensive, we have chosen not to do so for the moment. Instead, we choose to use a Runge-Kutta method, as implemented in scipy. This implementation is more intuitive and easier to extend, so we keep it for now. The same applies to the integral to calculate the the cumulative energy: we have used a Simpson method because it is more flexible but if it became a bottleneck, we could use a Romberg method (they are both implemented in scipy).","title":"The heat equation"},{"location":"thermo/#thermal-diffusivity","text":"We use a thermal diffusion model to simulate the heat transfer between rooms and to the outside of a school. We assume that the school and its internal walls are well insulated compared to the thermal conductivity of air, this is, we assume that the temperature in a room is almost constant with respect to the position inside it. We know there will be radiation effects (this is, rooms facing south will be warmer than rooms facing north when the heating is off) but we haven't taken them into account. We know there will be convection effects (this is, heat losses due to air currents), both from humans opening and closing the windows (but this we will never be able to model, at least not without extra information) and from the compulsory ventilation of the building. We haven't included a convection term, since it would make the simulation quite challenging, and we hope that the thermal loss due to built-in ventilation can be assimilated to diffusion losses through walls. We assume the school has some sort of automation built in for the heaters, so that they are able to turn on when there is a lecture and turn off when the room is not being used. Note we haven't done a full study of how a proper controller would work, since we haven't considered retrofitting effects into the controller. We have not considered other sources of heat, such as the people in the room, the light bulbs for illumination or the computers. Thus, we assume that the room is relatively \"large\" compared to the number of people \"crammed\" in. We can come back to this later, since it may have some impact in the optimization. These considerations result in a linear inhomogeneous system of ordinary differential equations. Even though we know it would be possible to transform the problem to the Laplace space to get a system of linear algebraic equations instead and then transform back, making the module less computationally expensive, we have chosen not to do so for the moment. Instead, we choose to use a Runge-Kutta method, as implemented in scipy. This implementation is more intuitive and easier to extend, so we keep it for now. The same applies to the integral to calculate the the cumulative energy: we have used a Simpson method because it is more flexible but if it became a bottleneck, we could use a Romberg method (they are both implemented in scipy).","title":"Thermal diffusivity"},{"location":"ml/dev/","text":"Development information for ML pipelines Creating a new pipeline for a new building / school: If you would like to add a machine learning model for a new school, you should do the following: mkdir buildings/<building_name> # This creates the directory, skip it if you already have one cd buildings/<building_name> dvc init --subdir git add . git commit -m \"Add dvc tracking for school <building_name>\" This will create a DVC project for the school and commit al the DVC metafiles and directories. You can read more on this here . After this, one needs a dvc.yaml and a params.yaml file in the buildings/<building_name> folder. We recommend copying the files in demo_school cp buildings/demo_school/dvc.yaml buildings/<building_name> cp buildings/demo_school/params.yaml buildings/<building_name> into the folder for the new building and modifying the params.yaml to fulfill your needs (In particular, to find the appropriate data source files under assets/ ). Then, running cd buildings/<building_name> && dvc exp run dvc.yaml will run the ML pipeline and you will be able to explore the results by examining the files created under: buildings/<building_name>/model/ Testing: The GitHub repository for thermo includes a number of tests to ensure the quality of the ML pipelines. Unit tests: Unit tests have been written to ensure the integrity of the different components of the pipeline. They can be found here . These tests are run, together with the other unit tests of the project, as part of the testing/pytest job every time code is pushed to the repository. Intergrity test for all pipelines: The job testing/test_dvc is run every time a pull request is opened in this repository. This component does a dry run of all the dvc pipelines under buildings , that is: bulidings/*/dvc.yaml . This checks that the pipeline files are understandable to dvc themselves, but does not ensure that they run with no errors (that will depend on the data, among other things). ML integration tests: ML integration tests check that the quality of results of the DVC pipeline for demo-school . As such, they need the files the pipeline generates. They are marked with ml_integration and they don't run unless they are specifically called for. The code for the ml_integration tests can be found under tests/integration_tests/test_mlworkflow . Running ML integration tests locally First, you will need to run the demo_school pipeline, as: cd buildings/demo_school/ dvc exp run dvc.yaml cd ../.. This will generate the files in the folders buildings/demo_school/data and buildings/demo_school/model that the integration tests need. Then you can run the test as: pytest -m ml_integration Running the ml_integration tests in GitHub Actions: The ML integration tests are run automatically every time a pull request is opened, if the dvc integrity tests complete. The job first runs the demo_school dvc pipeline and then runs the tests marked as ml_integration .","title":"Development"},{"location":"ml/dev/#development-information-for-ml-pipelines","text":"","title":"Development information for ML pipelines"},{"location":"ml/dev/#creating-a-new-pipeline-for-a-new-building-school","text":"If you would like to add a machine learning model for a new school, you should do the following: mkdir buildings/<building_name> # This creates the directory, skip it if you already have one cd buildings/<building_name> dvc init --subdir git add . git commit -m \"Add dvc tracking for school <building_name>\" This will create a DVC project for the school and commit al the DVC metafiles and directories. You can read more on this here . After this, one needs a dvc.yaml and a params.yaml file in the buildings/<building_name> folder. We recommend copying the files in demo_school cp buildings/demo_school/dvc.yaml buildings/<building_name> cp buildings/demo_school/params.yaml buildings/<building_name> into the folder for the new building and modifying the params.yaml to fulfill your needs (In particular, to find the appropriate data source files under assets/ ). Then, running cd buildings/<building_name> && dvc exp run dvc.yaml will run the ML pipeline and you will be able to explore the results by examining the files created under: buildings/<building_name>/model/","title":"Creating a new pipeline for a new building / school:"},{"location":"ml/dev/#testing","text":"The GitHub repository for thermo includes a number of tests to ensure the quality of the ML pipelines.","title":"Testing:"},{"location":"ml/dev/#unit-tests","text":"Unit tests have been written to ensure the integrity of the different components of the pipeline. They can be found here . These tests are run, together with the other unit tests of the project, as part of the testing/pytest job every time code is pushed to the repository.","title":"Unit tests:"},{"location":"ml/dev/#intergrity-test-for-all-pipelines","text":"The job testing/test_dvc is run every time a pull request is opened in this repository. This component does a dry run of all the dvc pipelines under buildings , that is: bulidings/*/dvc.yaml . This checks that the pipeline files are understandable to dvc themselves, but does not ensure that they run with no errors (that will depend on the data, among other things).","title":"Intergrity test for all pipelines:"},{"location":"ml/dev/#ml-integration-tests","text":"ML integration tests check that the quality of results of the DVC pipeline for demo-school . As such, they need the files the pipeline generates. They are marked with ml_integration and they don't run unless they are specifically called for. The code for the ml_integration tests can be found under tests/integration_tests/test_mlworkflow .","title":"ML integration tests:"},{"location":"ml/dev/#running-ml-integration-tests-locally","text":"First, you will need to run the demo_school pipeline, as: cd buildings/demo_school/ dvc exp run dvc.yaml cd ../.. This will generate the files in the folders buildings/demo_school/data and buildings/demo_school/model that the integration tests need. Then you can run the test as: pytest -m ml_integration","title":"Running ML integration tests locally"},{"location":"ml/dev/#running-the-ml_integration-tests-in-github-actions","text":"The ML integration tests are run automatically every time a pull request is opened, if the dvc integrity tests complete. The job first runs the demo_school dvc pipeline and then runs the tests marked as ml_integration .","title":"Running the ml_integration tests in GitHub Actions:"},{"location":"ml/usage/","text":"Using the ML pipelines Setup This project uses DVC (Data Version Control) for the version control of datasets and machine learning models, as well as for organizing machine learning pipelines and workflows. In order to use it, it is necessary to install thermo with its development dependencies: poetry install --with dev Running an existing pipeline To create a model to extract hyperparameters for a given building run the following: cd buildings/<building_name> dvc exp run dvc.yaml For example, for Strandskolen in Aarhus kommune this would be: cd buildings/strandskolen dvc exp run dvc.yaml Troubleshooting Make sure to store that the source data is stored in the assets directory into csv files, so that the pipeline is able to find them. You might need to indicate to the pipeline the name and the contents of the original files. This can be done by modifying the params.yaml file in the building/<building_name> folder.","title":"Usage"},{"location":"ml/usage/#using-the-ml-pipelines","text":"","title":"Using the ML pipelines"},{"location":"ml/usage/#setup","text":"This project uses DVC (Data Version Control) for the version control of datasets and machine learning models, as well as for organizing machine learning pipelines and workflows. In order to use it, it is necessary to install thermo with its development dependencies: poetry install --with dev","title":"Setup"},{"location":"ml/usage/#running-an-existing-pipeline","text":"To create a model to extract hyperparameters for a given building run the following: cd buildings/<building_name> dvc exp run dvc.yaml For example, for Strandskolen in Aarhus kommune this would be: cd buildings/strandskolen dvc exp run dvc.yaml","title":"Running an existing pipeline"},{"location":"ml/usage/#troubleshooting","text":"Make sure to store that the source data is stored in the assets directory into csv files, so that the pipeline is able to find them. You might need to indicate to the pipeline the name and the contents of the original files. This can be done by modifying the params.yaml file in the building/<building_name> folder.","title":"Troubleshooting"},{"location":"ml/workflow/","text":"Description of the workflow and its components: The machine learning workflow is described by the dvc.yaml file under each building folder. For example, the workflow for te demo_school is buildings/demo_school/dvc.yaml . Each machine learning workflow is split into several steps that are executed sequentially, as illustrated by the following graph: Each step executes a python script, which can be found under thermo/stages passing a set of parameters specific for that building, stored in the params.yml file ( buildings/<building_name>/params.yaml ) and produces some files that are stored under the data/ or model/ folder ( buildings/<building_name>/data and buildings/<building_name>/model ). In the following we describe the content of each script and what the parameters involved are. The specifics on how it works can be found in the API reference of this documentation. Get data This script takes data from different data sources, stored as csv files under assets/ , selects the relevant subset of data. This involves things like the specific building , the year or the measure_point for the energy sources. It then formats the data into a row per time stamp with a column per room and add columns with energy information. Takes in: .csv files under assets Outputs: raw_data.pkl under the data/ folder for the building Parameters: ## General parameters for the workflow building : demo_school # name of the building as in the data file municipality : demo_municipality # name of the municipality as in the data file year : 2022 # year of the dataset used ## Parameters specific to get_data.py step get_data : files : # list of files with data. Each must contain a name, filepath and parse_params - name : bookings file_path : assets/demo_bookings.csv parse_params : drop_empty_rooms : true aggregation_method : binary - name : energy file_path : assets/demo_energy.csv parse_params : measure_points : - 12892834 measure_types : - electricity Files in params.yaml for get_data must be described by a name , a filepath and a parse_params \"dictionary\" with the parameters to parse. name : The type of information in the file, currently only bookings and energy are implemented. file_path : Path to the csv file containing the data relative to the main directory of the repository. parse_params : additional parameters to parse the file. These parameters will depend on the type of file. parse_params for bookings files: drop_empty_rooms : boolean. Weather to create columns for rooms that have never been booked or not. aggregation_method : This can be binary or fractional . Binary will assign 1 if the room was booked and 0 otherwise. Fractional will assign the percentage of the time slot during which the rooms was booked (fx: if the room was booked between 17:30 and 18:00, it will assign 0.5 to the that room for the time slot 17:00-18:00) parse_params for energy files: measure_points : List of measure points whose energy measure is included in the ML dataset. measure_type : Type of measurement (electricty, water, ...) as spelled in the dataset. Preprocessing This script takes care of the feature engineering: it produces the insights we know are there so they can be fed to the machine learning algorithm in the next step. It takes in the raw bookings and does two main tasks: - Drops data that is not interesting - Feature engineering: simulates the ventilation system. Takes in: raw_data.pkl under the data/ folder for the building Outputs: preprocessed_data.pkl under the data/ folder for the building Parameters: ## Parameters specific to preprocessing.py step preprocessing : booking_hours_threshold : 0 drop_nights_and_school_hours : true ventilation : is_day : true booking_hours_threshold (int): rooms that have been booked less hours than this threshold will be dropped by the pipeline. drop_nights_and_school_hours (bool): If True drops the hours between midnight and the start of the booking period (this hour is defined in thermo/config.py ) mock_ventilation : can be is_day:True or is_on:True : is_on:True results in one hot encoding of whether the ventilation is on is_day:True results in a distinction between if the room was booked or it wasn't but the ventilation is in day mode. Train Train a linear regression to extract the cost of booking each room from the data. The model is trained using n-fold cross validation and grid search to decide the value of the \\(\\ell_2\\) regularization( see documentation for ridge regression ) that best fits the data. Takes in: preprocessed_data.pkl under the data/ folder for the building Outputs: model/model.joblib : File containing the model, makes it possible to use it to predict things later. model/model.metadata : Summary of the model chosen using cross-validation. Human readable. model/cross_validation.csv : Table with the full information about all cross-validation experiments. Parameters: ## Parameters specific to preprocessing.py step train : target : electricity # name of the target variable estimator : RidgeRegression # name of the regression algorithm cv_folds : 5 # number of cross validation folds alpha_min : 0.01 # min L2 regularization for grid search alpha_max : 100 # max L2 regularization for grid search Note : Currently, only RidgeRegression is supported as estimator. Evaluate_model This script validates the results of the rest of the workflow and produces plots and charts so that the quality can be further evaluated by the user. It doesn't take any parameters. Takes in: preprocessed_data.pkl under the data/ folder for the building model/model.joblib : File containing the model, makes it possible to use it to predict things later. model/cross_validation.csv : Table with the full information about all cross-validation experiments. Outputs: model/train.json & model/test.json : Train and test metrics ( \\(r^2\\) and RMSE) for the optimal hyperparameters, as averaged over cross validation folds. model/costs.csv - Extracts the costs of heating and keeping warm the rooms of the building and validates the result. model/error_distribution.png - plots the error distribution of the fit. The prediction for all points is the test set prediction from fold where that point was in the test set. Here is the result on the demo data set. model/regularization.png : plot of the result of the grid search for the regularization.","title":"Description"},{"location":"ml/workflow/#description-of-the-workflow-and-its-components","text":"The machine learning workflow is described by the dvc.yaml file under each building folder. For example, the workflow for te demo_school is buildings/demo_school/dvc.yaml . Each machine learning workflow is split into several steps that are executed sequentially, as illustrated by the following graph: Each step executes a python script, which can be found under thermo/stages passing a set of parameters specific for that building, stored in the params.yml file ( buildings/<building_name>/params.yaml ) and produces some files that are stored under the data/ or model/ folder ( buildings/<building_name>/data and buildings/<building_name>/model ). In the following we describe the content of each script and what the parameters involved are. The specifics on how it works can be found in the API reference of this documentation.","title":"Description of the workflow and its components:"},{"location":"ml/workflow/#get-data","text":"This script takes data from different data sources, stored as csv files under assets/ , selects the relevant subset of data. This involves things like the specific building , the year or the measure_point for the energy sources. It then formats the data into a row per time stamp with a column per room and add columns with energy information.","title":"Get data"},{"location":"ml/workflow/#takes-in","text":".csv files under assets","title":"Takes in:"},{"location":"ml/workflow/#outputs","text":"raw_data.pkl under the data/ folder for the building","title":"Outputs:"},{"location":"ml/workflow/#parameters","text":"## General parameters for the workflow building : demo_school # name of the building as in the data file municipality : demo_municipality # name of the municipality as in the data file year : 2022 # year of the dataset used ## Parameters specific to get_data.py step get_data : files : # list of files with data. Each must contain a name, filepath and parse_params - name : bookings file_path : assets/demo_bookings.csv parse_params : drop_empty_rooms : true aggregation_method : binary - name : energy file_path : assets/demo_energy.csv parse_params : measure_points : - 12892834 measure_types : - electricity Files in params.yaml for get_data must be described by a name , a filepath and a parse_params \"dictionary\" with the parameters to parse. name : The type of information in the file, currently only bookings and energy are implemented. file_path : Path to the csv file containing the data relative to the main directory of the repository. parse_params : additional parameters to parse the file. These parameters will depend on the type of file. parse_params for bookings files: drop_empty_rooms : boolean. Weather to create columns for rooms that have never been booked or not. aggregation_method : This can be binary or fractional . Binary will assign 1 if the room was booked and 0 otherwise. Fractional will assign the percentage of the time slot during which the rooms was booked (fx: if the room was booked between 17:30 and 18:00, it will assign 0.5 to the that room for the time slot 17:00-18:00) parse_params for energy files: measure_points : List of measure points whose energy measure is included in the ML dataset. measure_type : Type of measurement (electricty, water, ...) as spelled in the dataset.","title":"Parameters:"},{"location":"ml/workflow/#preprocessing","text":"This script takes care of the feature engineering: it produces the insights we know are there so they can be fed to the machine learning algorithm in the next step. It takes in the raw bookings and does two main tasks: - Drops data that is not interesting - Feature engineering: simulates the ventilation system.","title":"Preprocessing"},{"location":"ml/workflow/#takes-in_1","text":"raw_data.pkl under the data/ folder for the building","title":"Takes in:"},{"location":"ml/workflow/#outputs_1","text":"preprocessed_data.pkl under the data/ folder for the building","title":"Outputs:"},{"location":"ml/workflow/#parameters_1","text":"## Parameters specific to preprocessing.py step preprocessing : booking_hours_threshold : 0 drop_nights_and_school_hours : true ventilation : is_day : true booking_hours_threshold (int): rooms that have been booked less hours than this threshold will be dropped by the pipeline. drop_nights_and_school_hours (bool): If True drops the hours between midnight and the start of the booking period (this hour is defined in thermo/config.py ) mock_ventilation : can be is_day:True or is_on:True : is_on:True results in one hot encoding of whether the ventilation is on is_day:True results in a distinction between if the room was booked or it wasn't but the ventilation is in day mode.","title":"Parameters:"},{"location":"ml/workflow/#train","text":"Train a linear regression to extract the cost of booking each room from the data. The model is trained using n-fold cross validation and grid search to decide the value of the \\(\\ell_2\\) regularization( see documentation for ridge regression ) that best fits the data.","title":"Train"},{"location":"ml/workflow/#takes-in_2","text":"preprocessed_data.pkl under the data/ folder for the building","title":"Takes in:"},{"location":"ml/workflow/#outputs_2","text":"model/model.joblib : File containing the model, makes it possible to use it to predict things later. model/model.metadata : Summary of the model chosen using cross-validation. Human readable. model/cross_validation.csv : Table with the full information about all cross-validation experiments.","title":"Outputs:"},{"location":"ml/workflow/#parameters_2","text":"## Parameters specific to preprocessing.py step train : target : electricity # name of the target variable estimator : RidgeRegression # name of the regression algorithm cv_folds : 5 # number of cross validation folds alpha_min : 0.01 # min L2 regularization for grid search alpha_max : 100 # max L2 regularization for grid search Note : Currently, only RidgeRegression is supported as estimator.","title":"Parameters:"},{"location":"ml/workflow/#evaluate_model","text":"This script validates the results of the rest of the workflow and produces plots and charts so that the quality can be further evaluated by the user. It doesn't take any parameters.","title":"Evaluate_model"},{"location":"ml/workflow/#takes-in_3","text":"preprocessed_data.pkl under the data/ folder for the building model/model.joblib : File containing the model, makes it possible to use it to predict things later. model/cross_validation.csv : Table with the full information about all cross-validation experiments.","title":"Takes in:"},{"location":"ml/workflow/#outputs_3","text":"model/train.json & model/test.json : Train and test metrics ( \\(r^2\\) and RMSE) for the optimal hyperparameters, as averaged over cross validation folds. model/costs.csv - Extracts the costs of heating and keeping warm the rooms of the building and validates the result. model/error_distribution.png - plots the error distribution of the fit. The prediction for all points is the test set prediction from fold where that point was in the test set. Here is the result on the demo data set. model/regularization.png : plot of the result of the grid search for the regularization.","title":"Outputs:"},{"location":"ref/cost/","text":"CostName Names of all CostModel classes in thermo : HeatingCost , CapacityCost AmenityCost make_cost Creates a CostModel object given its name, and parameters. Parameters: Name Type Description Default name CostName Name of the CostModel class required kwargs other possible arguments to the init method of the CostModel. {} Returns: Type Description CostModel an instance of the name class. Source code in thermo/costs/__init__.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 def make_cost ( name : CostName , ** kwargs ) -> CostModel : \"\"\" Creates a CostModel object given its name, and parameters. Args: name: Name of the CostModel class kwargs: other possible arguments to the init method of the CostModel. Returns: an instance of the `name` class. \"\"\" match name : case \"HeatingCost\" : return HeatingCost ( ** kwargs ) case \"CapacityCost\" : return CapacityCost ( ** kwargs ) case \"AmenityCost\" : return AmenityCost ( ** kwargs ) case _ : raise NotImplementedError ( f \"CostModel { name } not implemented.\" ) HeatingCost HeatingCost ( * , adjacency : NDArray , t_weight : float = 1.0 , message_importance : float = 0.5 , heat_cost : NDArray | None = None , unavailable_cost : float = UNAVAILABLE_COST , ** kwargs ) Bases: CostModel Class to simulate the heating cost of a room. Args: adjacency: Adjacency matrix for space (n_rooms x n_rooms) tb_added. unavailable_cost: number associated to the room already being booked t_weight: weight of time in the adjacency matrix message_importance: weight of the message in the cost function heat_cost: cost of heating each room Source code in thermo/costs/heating.py 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 def __init__ ( self , * , adjacency : NDArray , t_weight : float = 1.0 , message_importance : float = 0.5 , heat_cost : NDArray | None = None , unavailable_cost : float = UNAVAILABLE_COST , ** kwargs ): \"\"\" Class to simulate the heating cost of a room. Args: adjacency: Adjacency matrix for space (n_rooms x n_rooms) tb_added. unavailable_cost: number associated to the room already being booked t_weight: weight of time in the adjacency matrix message_importance: weight of the message in the cost function heat_cost: cost of heating each room \"\"\" self . As = adjacency self . n_rooms = self . As . shape [ 0 ] self . t_weight = t_weight self . message_importance = message_importance self . heat_cost = heat_cost if heat_cost else np . ones ( self . n_rooms ) self . unavailable_cost = unavailable_cost run run ( state : NDArray , n_time_slots : int , ** kwargs ) -> NDArray Compute the cost of each possible booking given the current state of the booking. Parameters: Name Type Description Default state NDArray ones and zeros representing bookings shape = (n_rooms*n_time_slots,), required n_time_slots int number of time slots in the schedule (per day) required Returns: Name Type Description cost_vector NDArray where the lower the better. shape = (n_rooms*n_time_slots,), if room already booked, its np.nan Source code in thermo/costs/heating.py 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 def run ( self , state : NDArray , n_time_slots : int , ** kwargs ) -> NDArray : \"\"\" Compute the cost of each possible booking given the current state of the booking. Args: state: ones and zeros representing bookings shape = (n_rooms*n_time_slots,), n_time_slots: number of time slots in the schedule (per day) Returns: cost_vector: where the lower the better. shape = (n_rooms*n_time_slots,), if room already booked, its np.nan \"\"\" self . A = self . _get_full_graph ( n_time_slots = n_time_slots ) self . _full_heat_cost = self . _get_full_cost ( n_time_slots = n_time_slots ) out = self . _full_heat_cost - self . message_importance * np . matmul ( self . A , state ) return self . unavailable_cost * state + out CapacityCost CapacityCost ( room_descriptions : list [ Room ], capacity_utilization_coeff : float = 1.0 , unavailable_cost : float = UNAVAILABLE_COST , ** kwargs ) Bases: CostModel Class to simulate the capacity cost of a room: Room capacity cost is intuitively based on a Lennard-Jones potential function with a minimum at the required capacity. Rooms with capacity < required capacity have very high cost (unavailable_cost), while the cost for rooms with capacity = required capacity scales with the difference between the room capacity and required capacity. Note: We assume that room capacities are fixed across time. Parameters: Name Type Description Default room_descriptions list [ Room ] list of Room objects describing the rooms in the building required unavailable_cost float number associated to the room already being booked UNAVAILABLE_COST coefficent coefficient for adjusting the cost function to be more or less steep required Source code in thermo/costs/capacity.py 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 def __init__ ( self , room_descriptions : list [ Room ], capacity_utilization_coeff : float = 1.0 , unavailable_cost : float = UNAVAILABLE_COST , ** kwargs ): \"\"\" Class to simulate the capacity cost of a room: Room capacity cost is intuitively based on a Lennard-Jones potential function with a minimum at the required capacity. Rooms with `capacity` < `required capacity` have very high cost (unavailable_cost), while the cost for rooms with `capacity` >= `required capacity` scales with the difference between the room capacity and required capacity. Note: We assume that room capacities are fixed across time. Args: room_descriptions: list of Room objects describing the rooms in the building unavailable_cost: number associated to the room already being booked coefficent: coefficient for adjusting the cost function to be more or less steep \"\"\" self . room_descriptions = room_descriptions self . coeff = capacity_utilization_coeff self . unavailable_cost = unavailable_cost n_rooms property n_rooms : int Number of rooms room_capacities cached property room_capacities : NDArray Capacities of all rooms run run ( state : NDArray , n_time_slots : int , required_capacity : int = 10 , ** kwargs ) -> NDArray Calculate the capacity cost for each room-time combination, setting the cost to a very high number if the room is too small. Parameters: Name Type Description Default state NDArray ones and zeros representing bookings shape = (n_rooms, n_time_slots) required n_time_slots int number of time slots to consider required required_capacity int required room capacity to hold the party of the booker. 10 Returns: Name Type Description cost NDArray where the lower the better and very high if room is too small. Shape = (n_rooms*n_time_slots,) Source code in thermo/costs/capacity.py 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 def run ( self , state : NDArray , n_time_slots : int , required_capacity : int = 10 , ** kwargs ) -> NDArray : \"\"\" Calculate the capacity cost for each room-time combination, setting the cost to a very high number if the room is too small. Args: state: ones and zeros representing bookings shape = (n_rooms, n_time_slots) n_time_slots: number of time slots to consider required_capacity: required room capacity to hold the party of the booker. Returns: cost: where the lower the better and very high if room is too small. Shape = (n_rooms*n_time_slots,) \"\"\" _filter = self . room_capacities < required_capacity capacity_costs = self . _calculate_costs ( self . room_capacities , required_capacity ) room_costs = np . where ( _filter , self . unavailable_cost , capacity_costs ) # return explodes capacities to match state shape return np . tile ( room_costs , n_time_slots ) AmenityCost AmenityCost ( room_descriptions : list [ Room ], unavailable_cost : float = UNAVAILABLE_COST , amenity_utilization_coeff : float = 0.15 , ** kwargs ) Bases: CostModel Class to calculate the amenity cost of all rooms: Room amenities are functionalities inherent to each room, such as a screen projector, a whiteboard, musical instruments etc. Rooms without the amenities listed in required amenities have very high cost (denoted unavailable_cost). Conversely, the amenity cost of rooms with all or some of the amenities listed in required amenities scales with the difference between the number of amenities in the room and the number of required amenities. Note: We assume that room amenities are fixed across time. Parameters: Name Type Description Default room_descriptions list [ Room ] list of Room objects describing the rooms in the building required unavailable_cost float number assigned to a room w/o the needed amenities. UNAVAILABLE_COST coefficent coefficient for adjusting the cost function to be more or less steep required Source code in thermo/costs/amenity.py 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 def __init__ ( self , room_descriptions : list [ Room ], unavailable_cost : float = UNAVAILABLE_COST , amenity_utilization_coeff : float = 0.15 , ** kwargs ): \"\"\" Class to calculate the amenity cost of all rooms: Room amenities are functionalities inherent to each room, such as a screen projector, a whiteboard, musical instruments etc. Rooms without the amenities listed in `required amenities` have very high cost (denoted unavailable_cost). Conversely, the amenity cost of rooms with all or some of the amenities listed in `required amenities` scales with the difference between the number of amenities in the room and the number of required amenities. Note: We assume that room amenities are fixed across time. Args: room_descriptions: list of Room objects describing the rooms in the building unavailable_cost: number assigned to a room w/o the needed amenities. coefficent: coefficient for adjusting the cost function to be more or less steep \"\"\" self . room_descriptions = room_descriptions self . unavailable_cost = unavailable_cost self . coeff = amenity_utilization_coeff self . len_map = np . vectorize ( len ) room_amenities cached property room_amenities : list [ set [ str ]] Amenities of all rooms run run ( state : NDArray , n_time_slots : int , required_amenities : set [ str ] = set (), ** kwargs ) -> NDArray Calculate the amenity cost for each room-time combination, setting the cost to a very high number if the room does not have the required amenities, i.e. is not useful. Rooms are 'useful' when 'required_amenities' is a subset of the room amenities. For useful rooms, the cost is given by a parameterized discrepancy between of the number of amenities in the room and the number of required amenities. Parameters: Name Type Description Default state NDArray ones and zeros representing bookings shape = (n_rooms, n_time_slots) required n_time_slots int number of time slots to consider required required_amenities set [ str ] required amenities for the booking, e.g. {\"projector\", \"whiteboard\"} set () Returns: Name Type Description cost NDArray where the lower the better and very high if room does not have required amenities shape = (n_rooms*n_time_slots,) Source code in thermo/costs/amenity.py 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 def run ( self , state : NDArray , n_time_slots : int , required_amenities : set [ str ] = set (), # noqa: B006 ** kwargs ) -> NDArray : \"\"\" Calculate the amenity cost for each room-time combination, setting the cost to a very high number if the room does not have the required amenities, i.e. is not useful. Rooms are 'useful' when 'required_amenities' is a subset of the room amenities. For useful rooms, the cost is given by a parameterized discrepancy between of the number of amenities in the room and the number of required amenities. Args: state: ones and zeros representing bookings shape = (n_rooms, n_time_slots) n_time_slots: number of time slots to consider required_amenities: required amenities for the booking, e.g. {\"projector\", \"whiteboard\"} Returns: cost: where the lower the better and very high if room does not have required amenities shape = (n_rooms*n_time_slots,) \"\"\" useful_rooms = [ * map ( required_amenities . issubset , self . room_amenities )] utilization = self . _calculate_costs ( required_amenities ) costs = np . where ( useful_rooms , utilization , self . unavailable_cost ) # return exploded values to match state's shape return np . tile ( costs , n_time_slots )","title":"Costs"},{"location":"ref/cost/#costname","text":"Names of all CostModel classes in thermo : HeatingCost , CapacityCost AmenityCost","title":"CostName"},{"location":"ref/cost/#make_cost","text":"Creates a CostModel object given its name, and parameters. Parameters: Name Type Description Default name CostName Name of the CostModel class required kwargs other possible arguments to the init method of the CostModel. {} Returns: Type Description CostModel an instance of the name class. Source code in thermo/costs/__init__.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 def make_cost ( name : CostName , ** kwargs ) -> CostModel : \"\"\" Creates a CostModel object given its name, and parameters. Args: name: Name of the CostModel class kwargs: other possible arguments to the init method of the CostModel. Returns: an instance of the `name` class. \"\"\" match name : case \"HeatingCost\" : return HeatingCost ( ** kwargs ) case \"CapacityCost\" : return CapacityCost ( ** kwargs ) case \"AmenityCost\" : return AmenityCost ( ** kwargs ) case _ : raise NotImplementedError ( f \"CostModel { name } not implemented.\" )","title":"make_cost"},{"location":"ref/cost/#thermo.costs.heating.HeatingCost","text":"HeatingCost ( * , adjacency : NDArray , t_weight : float = 1.0 , message_importance : float = 0.5 , heat_cost : NDArray | None = None , unavailable_cost : float = UNAVAILABLE_COST , ** kwargs ) Bases: CostModel Class to simulate the heating cost of a room. Args: adjacency: Adjacency matrix for space (n_rooms x n_rooms) tb_added. unavailable_cost: number associated to the room already being booked t_weight: weight of time in the adjacency matrix message_importance: weight of the message in the cost function heat_cost: cost of heating each room Source code in thermo/costs/heating.py 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 def __init__ ( self , * , adjacency : NDArray , t_weight : float = 1.0 , message_importance : float = 0.5 , heat_cost : NDArray | None = None , unavailable_cost : float = UNAVAILABLE_COST , ** kwargs ): \"\"\" Class to simulate the heating cost of a room. Args: adjacency: Adjacency matrix for space (n_rooms x n_rooms) tb_added. unavailable_cost: number associated to the room already being booked t_weight: weight of time in the adjacency matrix message_importance: weight of the message in the cost function heat_cost: cost of heating each room \"\"\" self . As = adjacency self . n_rooms = self . As . shape [ 0 ] self . t_weight = t_weight self . message_importance = message_importance self . heat_cost = heat_cost if heat_cost else np . ones ( self . n_rooms ) self . unavailable_cost = unavailable_cost","title":"HeatingCost"},{"location":"ref/cost/#thermo.costs.heating.HeatingCost.run","text":"run ( state : NDArray , n_time_slots : int , ** kwargs ) -> NDArray Compute the cost of each possible booking given the current state of the booking. Parameters: Name Type Description Default state NDArray ones and zeros representing bookings shape = (n_rooms*n_time_slots,), required n_time_slots int number of time slots in the schedule (per day) required Returns: Name Type Description cost_vector NDArray where the lower the better. shape = (n_rooms*n_time_slots,), if room already booked, its np.nan Source code in thermo/costs/heating.py 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 def run ( self , state : NDArray , n_time_slots : int , ** kwargs ) -> NDArray : \"\"\" Compute the cost of each possible booking given the current state of the booking. Args: state: ones and zeros representing bookings shape = (n_rooms*n_time_slots,), n_time_slots: number of time slots in the schedule (per day) Returns: cost_vector: where the lower the better. shape = (n_rooms*n_time_slots,), if room already booked, its np.nan \"\"\" self . A = self . _get_full_graph ( n_time_slots = n_time_slots ) self . _full_heat_cost = self . _get_full_cost ( n_time_slots = n_time_slots ) out = self . _full_heat_cost - self . message_importance * np . matmul ( self . A , state ) return self . unavailable_cost * state + out","title":"run()"},{"location":"ref/cost/#thermo.costs.capacity.CapacityCost","text":"CapacityCost ( room_descriptions : list [ Room ], capacity_utilization_coeff : float = 1.0 , unavailable_cost : float = UNAVAILABLE_COST , ** kwargs ) Bases: CostModel Class to simulate the capacity cost of a room: Room capacity cost is intuitively based on a Lennard-Jones potential function with a minimum at the required capacity. Rooms with capacity < required capacity have very high cost (unavailable_cost), while the cost for rooms with capacity = required capacity scales with the difference between the room capacity and required capacity. Note: We assume that room capacities are fixed across time. Parameters: Name Type Description Default room_descriptions list [ Room ] list of Room objects describing the rooms in the building required unavailable_cost float number associated to the room already being booked UNAVAILABLE_COST coefficent coefficient for adjusting the cost function to be more or less steep required Source code in thermo/costs/capacity.py 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 def __init__ ( self , room_descriptions : list [ Room ], capacity_utilization_coeff : float = 1.0 , unavailable_cost : float = UNAVAILABLE_COST , ** kwargs ): \"\"\" Class to simulate the capacity cost of a room: Room capacity cost is intuitively based on a Lennard-Jones potential function with a minimum at the required capacity. Rooms with `capacity` < `required capacity` have very high cost (unavailable_cost), while the cost for rooms with `capacity` >= `required capacity` scales with the difference between the room capacity and required capacity. Note: We assume that room capacities are fixed across time. Args: room_descriptions: list of Room objects describing the rooms in the building unavailable_cost: number associated to the room already being booked coefficent: coefficient for adjusting the cost function to be more or less steep \"\"\" self . room_descriptions = room_descriptions self . coeff = capacity_utilization_coeff self . unavailable_cost = unavailable_cost","title":"CapacityCost"},{"location":"ref/cost/#thermo.costs.capacity.CapacityCost.n_rooms","text":"n_rooms : int Number of rooms","title":"n_rooms"},{"location":"ref/cost/#thermo.costs.capacity.CapacityCost.room_capacities","text":"room_capacities : NDArray Capacities of all rooms","title":"room_capacities"},{"location":"ref/cost/#thermo.costs.capacity.CapacityCost.run","text":"run ( state : NDArray , n_time_slots : int , required_capacity : int = 10 , ** kwargs ) -> NDArray Calculate the capacity cost for each room-time combination, setting the cost to a very high number if the room is too small. Parameters: Name Type Description Default state NDArray ones and zeros representing bookings shape = (n_rooms, n_time_slots) required n_time_slots int number of time slots to consider required required_capacity int required room capacity to hold the party of the booker. 10 Returns: Name Type Description cost NDArray where the lower the better and very high if room is too small. Shape = (n_rooms*n_time_slots,) Source code in thermo/costs/capacity.py 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 def run ( self , state : NDArray , n_time_slots : int , required_capacity : int = 10 , ** kwargs ) -> NDArray : \"\"\" Calculate the capacity cost for each room-time combination, setting the cost to a very high number if the room is too small. Args: state: ones and zeros representing bookings shape = (n_rooms, n_time_slots) n_time_slots: number of time slots to consider required_capacity: required room capacity to hold the party of the booker. Returns: cost: where the lower the better and very high if room is too small. Shape = (n_rooms*n_time_slots,) \"\"\" _filter = self . room_capacities < required_capacity capacity_costs = self . _calculate_costs ( self . room_capacities , required_capacity ) room_costs = np . where ( _filter , self . unavailable_cost , capacity_costs ) # return explodes capacities to match state shape return np . tile ( room_costs , n_time_slots )","title":"run()"},{"location":"ref/cost/#thermo.costs.amenity.AmenityCost","text":"AmenityCost ( room_descriptions : list [ Room ], unavailable_cost : float = UNAVAILABLE_COST , amenity_utilization_coeff : float = 0.15 , ** kwargs ) Bases: CostModel Class to calculate the amenity cost of all rooms: Room amenities are functionalities inherent to each room, such as a screen projector, a whiteboard, musical instruments etc. Rooms without the amenities listed in required amenities have very high cost (denoted unavailable_cost). Conversely, the amenity cost of rooms with all or some of the amenities listed in required amenities scales with the difference between the number of amenities in the room and the number of required amenities. Note: We assume that room amenities are fixed across time. Parameters: Name Type Description Default room_descriptions list [ Room ] list of Room objects describing the rooms in the building required unavailable_cost float number assigned to a room w/o the needed amenities. UNAVAILABLE_COST coefficent coefficient for adjusting the cost function to be more or less steep required Source code in thermo/costs/amenity.py 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 def __init__ ( self , room_descriptions : list [ Room ], unavailable_cost : float = UNAVAILABLE_COST , amenity_utilization_coeff : float = 0.15 , ** kwargs ): \"\"\" Class to calculate the amenity cost of all rooms: Room amenities are functionalities inherent to each room, such as a screen projector, a whiteboard, musical instruments etc. Rooms without the amenities listed in `required amenities` have very high cost (denoted unavailable_cost). Conversely, the amenity cost of rooms with all or some of the amenities listed in `required amenities` scales with the difference between the number of amenities in the room and the number of required amenities. Note: We assume that room amenities are fixed across time. Args: room_descriptions: list of Room objects describing the rooms in the building unavailable_cost: number assigned to a room w/o the needed amenities. coefficent: coefficient for adjusting the cost function to be more or less steep \"\"\" self . room_descriptions = room_descriptions self . unavailable_cost = unavailable_cost self . coeff = amenity_utilization_coeff self . len_map = np . vectorize ( len )","title":"AmenityCost"},{"location":"ref/cost/#thermo.costs.amenity.AmenityCost.room_amenities","text":"room_amenities : list [ set [ str ]] Amenities of all rooms","title":"room_amenities"},{"location":"ref/cost/#thermo.costs.amenity.AmenityCost.run","text":"run ( state : NDArray , n_time_slots : int , required_amenities : set [ str ] = set (), ** kwargs ) -> NDArray Calculate the amenity cost for each room-time combination, setting the cost to a very high number if the room does not have the required amenities, i.e. is not useful. Rooms are 'useful' when 'required_amenities' is a subset of the room amenities. For useful rooms, the cost is given by a parameterized discrepancy between of the number of amenities in the room and the number of required amenities. Parameters: Name Type Description Default state NDArray ones and zeros representing bookings shape = (n_rooms, n_time_slots) required n_time_slots int number of time slots to consider required required_amenities set [ str ] required amenities for the booking, e.g. {\"projector\", \"whiteboard\"} set () Returns: Name Type Description cost NDArray where the lower the better and very high if room does not have required amenities shape = (n_rooms*n_time_slots,) Source code in thermo/costs/amenity.py 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 def run ( self , state : NDArray , n_time_slots : int , required_amenities : set [ str ] = set (), # noqa: B006 ** kwargs ) -> NDArray : \"\"\" Calculate the amenity cost for each room-time combination, setting the cost to a very high number if the room does not have the required amenities, i.e. is not useful. Rooms are 'useful' when 'required_amenities' is a subset of the room amenities. For useful rooms, the cost is given by a parameterized discrepancy between of the number of amenities in the room and the number of required amenities. Args: state: ones and zeros representing bookings shape = (n_rooms, n_time_slots) n_time_slots: number of time slots to consider required_amenities: required amenities for the booking, e.g. {\"projector\", \"whiteboard\"} Returns: cost: where the lower the better and very high if room does not have required amenities shape = (n_rooms*n_time_slots,) \"\"\" useful_rooms = [ * map ( required_amenities . issubset , self . room_amenities )] utilization = self . _calculate_costs ( required_amenities ) costs = np . where ( useful_rooms , utilization , self . unavailable_cost ) # return exploded values to match state's shape return np . tile ( costs , n_time_slots )","title":"run()"},{"location":"ref/ranker/","text":"RankerName Names of all Ranker classes in thermo : FullRanker make_ranker Creates a Ranker object given its name, and the costs that it ranks. Parameters: Name Type Description Default ranker_name RankerName Name of the ranker required costs list [ CostModel ] Cost instances to compute the cost of each room. required kwargs other possible arguments to the init method of the ranker. {} Returns: Type Description Ranker an instance of the ranker_name class. Source code in thermo/ranker/__init__.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 def make_ranker ( ranker_name : RankerName , costs : list [ CostModel ], ** kwargs ) -> Ranker : \"\"\" Creates a Ranker object given its name, and the costs that it ranks. Args: ranker_name: Name of the ranker costs: Cost instances to compute the cost of each room. kwargs: other possible arguments to the init method of the ranker. Returns: an instance of the `ranker_name` class. \"\"\" match ranker_name : case \"FullRanker\" : ranker = FullRanker case _ : raise NotImplementedError ( f \"Ranker { ranker_name } not implemented\" ) return ranker ( costs = costs , ** kwargs ) FullRanker FullRanker ( costs : list [ CostModel ]) Bases: Ranker Calculates the cost for the full schedule: i.e. all rooms for all time slots. The total cost is computed as the sum of individual costs. Args: costs: list of instances of costs models to compute the costs from. Source code in thermo/ranker/full.py 17 18 def __init__ ( self , costs : list [ CostModel ]): super () . __init__ ( costs = costs ) run run ( state : NDArray , ** kwargs ) -> NDArray Adds up costs from individual cost sources, to return the cost of booking a given room for a given time slot. Args: state: state: a flat array containing 1 if the room is booked at that time a zero otherwise. kwargs: other possible arguments to the run method. Returns: Type Description NDArray An array of the same shape as the state, containing the costs. Source code in thermo/ranker/full.py 20 21 22 23 24 25 26 27 28 29 30 31 32 def run ( self , state : NDArray , ** kwargs ) -> NDArray : \"\"\" Adds up costs from individual cost sources, to return the cost of booking a given room for a given time slot. Args: state: state: a flat array containing 1 if the room is booked at that time a zero otherwise. kwargs: other possible arguments to the run method. Returns: An array of the same shape as the state, containing the costs. \"\"\" return np . sum ([ cost . run ( state , ** kwargs ) for cost in self . costs ], axis = 0 )","title":"Rankers"},{"location":"ref/ranker/#rankername","text":"Names of all Ranker classes in thermo : FullRanker","title":"RankerName"},{"location":"ref/ranker/#make_ranker","text":"Creates a Ranker object given its name, and the costs that it ranks. Parameters: Name Type Description Default ranker_name RankerName Name of the ranker required costs list [ CostModel ] Cost instances to compute the cost of each room. required kwargs other possible arguments to the init method of the ranker. {} Returns: Type Description Ranker an instance of the ranker_name class. Source code in thermo/ranker/__init__.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 def make_ranker ( ranker_name : RankerName , costs : list [ CostModel ], ** kwargs ) -> Ranker : \"\"\" Creates a Ranker object given its name, and the costs that it ranks. Args: ranker_name: Name of the ranker costs: Cost instances to compute the cost of each room. kwargs: other possible arguments to the init method of the ranker. Returns: an instance of the `ranker_name` class. \"\"\" match ranker_name : case \"FullRanker\" : ranker = FullRanker case _ : raise NotImplementedError ( f \"Ranker { ranker_name } not implemented\" ) return ranker ( costs = costs , ** kwargs )","title":"make_ranker"},{"location":"ref/ranker/#thermo.ranker.full.FullRanker","text":"FullRanker ( costs : list [ CostModel ]) Bases: Ranker Calculates the cost for the full schedule: i.e. all rooms for all time slots. The total cost is computed as the sum of individual costs. Args: costs: list of instances of costs models to compute the costs from. Source code in thermo/ranker/full.py 17 18 def __init__ ( self , costs : list [ CostModel ]): super () . __init__ ( costs = costs )","title":"FullRanker"},{"location":"ref/ranker/#thermo.ranker.full.FullRanker.run","text":"run ( state : NDArray , ** kwargs ) -> NDArray Adds up costs from individual cost sources, to return the cost of booking a given room for a given time slot. Args: state: state: a flat array containing 1 if the room is booked at that time a zero otherwise. kwargs: other possible arguments to the run method. Returns: Type Description NDArray An array of the same shape as the state, containing the costs. Source code in thermo/ranker/full.py 20 21 22 23 24 25 26 27 28 29 30 31 32 def run ( self , state : NDArray , ** kwargs ) -> NDArray : \"\"\" Adds up costs from individual cost sources, to return the cost of booking a given room for a given time slot. Args: state: state: a flat array containing 1 if the room is booked at that time a zero otherwise. kwargs: other possible arguments to the run method. Returns: An array of the same shape as the state, containing the costs. \"\"\" return np . sum ([ cost . run ( state , ** kwargs ) for cost in self . costs ], axis = 0 )","title":"run()"},{"location":"ref/recommender/","text":"Recommender Recommendation Recommendation ( ranking : NDArray , room_names : list [ str ]) Class to contain the postprocessing of recommendations. Args: ranking: the output of a Ranker.run call. room_names: names of the rooms for display Source code in thermo/recommender.py 28 29 def __init__ ( self , ranking : NDArray , room_names : list [ str ]): self . ranking = to_frame ( ranking , room_names = room_names ) show show () -> Styler Returns a styled DataFrame with a color gradient. Formats the DataFrame to 1 decimal place and replaces NaN values with blank value. Returns: Type Description Styler pandas.io.formats.style.Styler: styled DataFrame Source code in thermo/recommender.py 31 32 33 34 35 36 37 38 39 40 def show ( self ) -> Styler : \"\"\" Returns a styled DataFrame with a color gradient. Formats the DataFrame to 1 decimal place and replaces NaN values with blank value. Returns: pandas.io.formats.style.Styler: styled DataFrame \"\"\" return show_recommendations ( self . ranking ) top_recommendations top_recommendations () -> pd . Series Returns a sorted list of recommendations, with columns \"Time Slot\", \"Room\", \"Score\" Source code in thermo/recommender.py 49 50 51 52 53 54 def top_recommendations ( self ) -> pd . Series : \"\"\" Returns a sorted list of recommendations, with columns \"Time Slot\", \"Room\", \"Score\" \"\"\" return list_recommendations ( self . ranking ) Recommender Recommender ( building : Building , ranker : Ranker ) Interface for GUI or API to interact with the rest of thermo. Init method, intended for testing purposes and not for human use. We recommend instantiating recommenders from config files by calling Recommender.from_config(school_name). Parameters: Name Type Description Default building Building Building object containing the adjacency matrix, room descriptions and costs etc. required ranker Ranker Object to orchestrate the different costs and how they are combined. Examples of costs are thermo.costs.HeatingCost or thermo.costs.CapacityCost . required Source code in thermo/recommender.py 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 def __init__ ( self , building : Building , ranker : Ranker , ): \"\"\" Init method, intended for testing purposes and not for human use. We recommend instantiating recommenders from config files by calling Recommender.from_config(school_name). Args: building: Building object containing the adjacency matrix, room descriptions and costs etc. ranker: Object to orchestrate the different costs and how they are combined. Examples of costs are `thermo.costs.HeatingCost` or `thermo.costs.CapacityCost`. \"\"\" self . building = building self . _room_names = building . get_room_attr ( \"name\" ) self . ranker = ranker from_config classmethod from_config ( building_name : str ) -> Recommender Creates a Recommender from the config files of a building. Parameters: Name Type Description Default building_name str Name of the building, as in the path to its config files. required Returns: Type Description Recommender A recommender based on the configuration for that building found in buildings/building_name . Source code in thermo/recommender.py 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 @classmethod def from_config ( cls , building_name : str ) -> \"Recommender\" : \"\"\" Creates a Recommender from the config files of a building. Args: building_name: Name of the building, as in the path to its config files. Returns: A recommender based on the configuration for that building found in `buildings/building_name`. \"\"\" building_path = io . get_building_path ( building_name ) building = io . load_building ( building_path ) costs = [ make_cost ( name = key , adjacency = building . adjacency , room_descriptions = building . room_descriptions , ** values , ) for key , values in building . costs . items () ] ranker = make_ranker ( ranker_name = building . ranker , costs = costs ) return cls ( building = building , ranker = ranker , ) run run ( day : date , ** kwargs ) -> Recommendation Produces a recommendation of which rooms to book given a date. The method calls internally the schools API to determine which books have been already booked. It then calls all the costs and combines them according to the ranker, to return an instance of Recommendation, with all the costs for the rooms. Parameters: Name Type Description Default day date date for which the user desires make a booking. required kwargs other possible run-time parameters for the costs. {} Returns: Type Description Recommendation The costs of the recommended possible bookings. Source code in thermo/recommender.py 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 def run ( self , day : date , ** kwargs ) -> Recommendation : \"\"\" Produces a recommendation of which rooms to book given a date. The method calls internally the schools API to determine which books have been already booked. It then calls all the costs and combines them according to the ranker, to return an instance of Recommendation, with all the costs for the rooms. Args: day: date for which the user desires make a booking. kwargs: other possible run-time parameters for the costs. Returns: The costs of the recommended possible bookings. \"\"\" state = get_state ( day ) n_time_slots = get_time_slots ( day ) recommendation = self . ranker . run ( state , n_time_slots = n_time_slots , ** kwargs ) return Recommendation ( recommendation , room_names = self . _room_names )","title":"Recommender and Recommendation"},{"location":"ref/recommender/#recommender","text":"","title":"Recommender"},{"location":"ref/recommender/#thermo.recommender.Recommendation","text":"Recommendation ( ranking : NDArray , room_names : list [ str ]) Class to contain the postprocessing of recommendations. Args: ranking: the output of a Ranker.run call. room_names: names of the rooms for display Source code in thermo/recommender.py 28 29 def __init__ ( self , ranking : NDArray , room_names : list [ str ]): self . ranking = to_frame ( ranking , room_names = room_names )","title":"Recommendation"},{"location":"ref/recommender/#thermo.recommender.Recommendation.show","text":"show () -> Styler Returns a styled DataFrame with a color gradient. Formats the DataFrame to 1 decimal place and replaces NaN values with blank value. Returns: Type Description Styler pandas.io.formats.style.Styler: styled DataFrame Source code in thermo/recommender.py 31 32 33 34 35 36 37 38 39 40 def show ( self ) -> Styler : \"\"\" Returns a styled DataFrame with a color gradient. Formats the DataFrame to 1 decimal place and replaces NaN values with blank value. Returns: pandas.io.formats.style.Styler: styled DataFrame \"\"\" return show_recommendations ( self . ranking )","title":"show()"},{"location":"ref/recommender/#thermo.recommender.Recommendation.top_recommendations","text":"top_recommendations () -> pd . Series Returns a sorted list of recommendations, with columns \"Time Slot\", \"Room\", \"Score\" Source code in thermo/recommender.py 49 50 51 52 53 54 def top_recommendations ( self ) -> pd . Series : \"\"\" Returns a sorted list of recommendations, with columns \"Time Slot\", \"Room\", \"Score\" \"\"\" return list_recommendations ( self . ranking )","title":"top_recommendations()"},{"location":"ref/recommender/#thermo.recommender.Recommender","text":"Recommender ( building : Building , ranker : Ranker ) Interface for GUI or API to interact with the rest of thermo. Init method, intended for testing purposes and not for human use. We recommend instantiating recommenders from config files by calling Recommender.from_config(school_name). Parameters: Name Type Description Default building Building Building object containing the adjacency matrix, room descriptions and costs etc. required ranker Ranker Object to orchestrate the different costs and how they are combined. Examples of costs are thermo.costs.HeatingCost or thermo.costs.CapacityCost . required Source code in thermo/recommender.py 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 def __init__ ( self , building : Building , ranker : Ranker , ): \"\"\" Init method, intended for testing purposes and not for human use. We recommend instantiating recommenders from config files by calling Recommender.from_config(school_name). Args: building: Building object containing the adjacency matrix, room descriptions and costs etc. ranker: Object to orchestrate the different costs and how they are combined. Examples of costs are `thermo.costs.HeatingCost` or `thermo.costs.CapacityCost`. \"\"\" self . building = building self . _room_names = building . get_room_attr ( \"name\" ) self . ranker = ranker","title":"Recommender"},{"location":"ref/recommender/#thermo.recommender.Recommender.from_config","text":"from_config ( building_name : str ) -> Recommender Creates a Recommender from the config files of a building. Parameters: Name Type Description Default building_name str Name of the building, as in the path to its config files. required Returns: Type Description Recommender A recommender based on the configuration for that building found in buildings/building_name . Source code in thermo/recommender.py 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 @classmethod def from_config ( cls , building_name : str ) -> \"Recommender\" : \"\"\" Creates a Recommender from the config files of a building. Args: building_name: Name of the building, as in the path to its config files. Returns: A recommender based on the configuration for that building found in `buildings/building_name`. \"\"\" building_path = io . get_building_path ( building_name ) building = io . load_building ( building_path ) costs = [ make_cost ( name = key , adjacency = building . adjacency , room_descriptions = building . room_descriptions , ** values , ) for key , values in building . costs . items () ] ranker = make_ranker ( ranker_name = building . ranker , costs = costs ) return cls ( building = building , ranker = ranker , )","title":"from_config()"},{"location":"ref/recommender/#thermo.recommender.Recommender.run","text":"run ( day : date , ** kwargs ) -> Recommendation Produces a recommendation of which rooms to book given a date. The method calls internally the schools API to determine which books have been already booked. It then calls all the costs and combines them according to the ranker, to return an instance of Recommendation, with all the costs for the rooms. Parameters: Name Type Description Default day date date for which the user desires make a booking. required kwargs other possible run-time parameters for the costs. {} Returns: Type Description Recommendation The costs of the recommended possible bookings. Source code in thermo/recommender.py 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 def run ( self , day : date , ** kwargs ) -> Recommendation : \"\"\" Produces a recommendation of which rooms to book given a date. The method calls internally the schools API to determine which books have been already booked. It then calls all the costs and combines them according to the ranker, to return an instance of Recommendation, with all the costs for the rooms. Args: day: date for which the user desires make a booking. kwargs: other possible run-time parameters for the costs. Returns: The costs of the recommended possible bookings. \"\"\" state = get_state ( day ) n_time_slots = get_time_slots ( day ) recommendation = self . ranker . run ( state , n_time_slots = n_time_slots , ** kwargs ) return Recommendation ( recommendation , room_names = self . _room_names )","title":"run()"},{"location":"ref/ml/evaluate/","text":"evaluate_model.py This script validates the results of the rest of the workflow and produces plots and charts so that the quality can be further evaluated by the user. extract_coefficients extract_coefficients ( dataf : pd . DataFrame , model : RegressorMixin ) -> pd . DataFrame Extracts the cost coefficients for different room from the model. Parameters: Name Type Description Default dataf DataFrame The training set. required model RegressorMixin Fitted regression model. required Returns: Type Description DataFrame DataFrame with the cost coefficients of the rooms given their status. Source code in thermo/stages/evaluate_model.py 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 def extract_coefficients ( dataf : pd . DataFrame , model : RegressorMixin ) -> pd . DataFrame : \"\"\" Extracts the cost coefficients for different room from the model. Args: dataf: The training set. model: Fitted regression model. Returns: DataFrame with the cost coefficients of the rooms given their status. \"\"\" names = [ col for col in dataf . columns if col . endswith ( \"booked\" ) or col . endswith ( \"day\" ) ] return pd . DataFrame ( { \"room\" : map ( lambda x : x . split ( \"_\" )[ 0 ], names ), \"status\" : map ( lambda x : x . split ( \"_\" )[ 1 ], names ), \"cost\" : model . named_steps [ \"regression\" ] . coef_ [: len ( names )], } ) . pivot ( columns = \"status\" , index = \"room\" , values = \"cost\" ) get_metrics get_metrics ( dataf : pd . DataFrame , nfolds : int , which : str = 'test' ) -> dict [ str , Any ] Returns metrics of the best model from grid search results. Parameters: Name Type Description Default dataf DataFrame Grid search results. required nfolds int Number of cross-validation folds in dataf. required which str The type of metrics to retrieve (\"test\" or \"train\"). 'test' Returns: Name Type Description dict dict [ str , Any ] Dictionary containing the metrics. Source code in thermo/stages/evaluate_model.py 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 def get_metrics ( dataf : pd . DataFrame , nfolds : int , which : str = \"test\" ) -> dict [ str , Any ]: \"\"\" Returns metrics of the best model from grid search results. Args: dataf: Grid search results. nfolds: Number of cross-validation folds in dataf. which: The type of metrics to retrieve (\"test\" or \"train\"). Defaults to \"test\". Returns: dict: Dictionary containing the metrics. \"\"\" idx = dataf [ \"mean_test_r2\" ] . argmax () best_model = dataf . iloc [ idx ] return { \"r2\" : best_model [ f \"mean_ { which } _r2\" ], \"r2_err\" : best_model [ f \"std_ { which } _r2\" ] / sqrt ( nfolds ), \"rmse\" : - best_model [ f \"mean_ { which } _neg_root_mean_squared_error\" ], \"rmse_err\" : best_model [ f \"std_ { which } _neg_root_mean_squared_error\" ] / sqrt ( nfolds ), # noqa W503 } plot_error_distribution plot_error_distribution ( model : RegressorMixin , dataf : pd . DataFrame , target : str , figpath : Path ) -> None Creates the scatter plot showing the relationship between the true and predicted values. Parameters: Name Type Description Default model RegressorMixin Fitted regression model. required dataf DataFrame training set. required target str Name of the target column. required figpath Path Filepath to save the plot. required Source code in thermo/stages/evaluate_model.py 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 def plot_error_distribution ( model : RegressorMixin , dataf : pd . DataFrame , target : str , figpath : Path ) -> None : \"\"\" Creates the scatter plot showing the relationship between the true and predicted values. Args: model: Fitted regression model. dataf: training set. target: Name of the target column. figpath: Filepath to save the plot. \"\"\" y_true = dataf [ target ] X = dataf . drop ( columns = target ) y_pred = model . predict ( X ) rmse = np . sqrt (( y_true - y_pred ) . pow ( 2 ) . mean ()) x = np . linspace ( y_pred . min (), y_pred . max (), 100 ) fig = sns . jointplot ( x = y_pred , y = y_true , alpha = 0.3 ) fig . ax_joint . plot ( x , x , \"k-\" , alpha = 0.5 ) fig . ax_joint . plot ( x , x + rmse , \"k--\" , alpha = 0.5 ) fig . ax_joint . plot ( x , x - rmse , \"k--\" , alpha = 0.5 ) fig . ax_joint . set_xlabel ( \"prediction (kWh)\" ) fig . ax_joint . set_ylabel ( \"consumption (kWh)\" ) fig . savefig ( figpath ) plot_gridsearch plot_gridsearch ( dataf : pd . DataFrame , nfolds : int , figpath : Path ) -> None Plots the results of the grid search for the L2 regularization. Parameters: Name Type Description Default dataf DataFrame Grid search results. required nfolds int Number of cross-validation folds in dataf. required figpath Path Filepath to save the plot. required Source code in thermo/stages/evaluate_model.py 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 def plot_gridsearch ( dataf : pd . DataFrame , nfolds : int , figpath : Path ) -> None : \"\"\"Plots the results of the grid search for the L2 regularization. Args: dataf: Grid search results. nfolds: Number of cross-validation folds in dataf. figpath: Filepath to save the plot. \"\"\" x = dataf [ \"param_regression__alpha\" ] y = dataf [ \"mean_test_r2\" ] y_err = dataf [ \"std_test_r2\" ] / sqrt ( nfolds ) plt . errorbar ( x , y , y_err ) plt . xscale ( \"log\" ) plt . ylabel ( \"r2 score\" ) plt . xlabel ( \"L2 regularization\" ) plt . title ( \"Grid search on the test set\" ) plt . savefig ( figpath )","title":"evaluate_model.py"},{"location":"ref/ml/evaluate/#evaluate_modelpy","text":"This script validates the results of the rest of the workflow and produces plots and charts so that the quality can be further evaluated by the user.","title":"evaluate_model.py"},{"location":"ref/ml/evaluate/#thermo.stages.evaluate_model.extract_coefficients","text":"extract_coefficients ( dataf : pd . DataFrame , model : RegressorMixin ) -> pd . DataFrame Extracts the cost coefficients for different room from the model. Parameters: Name Type Description Default dataf DataFrame The training set. required model RegressorMixin Fitted regression model. required Returns: Type Description DataFrame DataFrame with the cost coefficients of the rooms given their status. Source code in thermo/stages/evaluate_model.py 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 def extract_coefficients ( dataf : pd . DataFrame , model : RegressorMixin ) -> pd . DataFrame : \"\"\" Extracts the cost coefficients for different room from the model. Args: dataf: The training set. model: Fitted regression model. Returns: DataFrame with the cost coefficients of the rooms given their status. \"\"\" names = [ col for col in dataf . columns if col . endswith ( \"booked\" ) or col . endswith ( \"day\" ) ] return pd . DataFrame ( { \"room\" : map ( lambda x : x . split ( \"_\" )[ 0 ], names ), \"status\" : map ( lambda x : x . split ( \"_\" )[ 1 ], names ), \"cost\" : model . named_steps [ \"regression\" ] . coef_ [: len ( names )], } ) . pivot ( columns = \"status\" , index = \"room\" , values = \"cost\" )","title":"extract_coefficients()"},{"location":"ref/ml/evaluate/#thermo.stages.evaluate_model.get_metrics","text":"get_metrics ( dataf : pd . DataFrame , nfolds : int , which : str = 'test' ) -> dict [ str , Any ] Returns metrics of the best model from grid search results. Parameters: Name Type Description Default dataf DataFrame Grid search results. required nfolds int Number of cross-validation folds in dataf. required which str The type of metrics to retrieve (\"test\" or \"train\"). 'test' Returns: Name Type Description dict dict [ str , Any ] Dictionary containing the metrics. Source code in thermo/stages/evaluate_model.py 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 def get_metrics ( dataf : pd . DataFrame , nfolds : int , which : str = \"test\" ) -> dict [ str , Any ]: \"\"\" Returns metrics of the best model from grid search results. Args: dataf: Grid search results. nfolds: Number of cross-validation folds in dataf. which: The type of metrics to retrieve (\"test\" or \"train\"). Defaults to \"test\". Returns: dict: Dictionary containing the metrics. \"\"\" idx = dataf [ \"mean_test_r2\" ] . argmax () best_model = dataf . iloc [ idx ] return { \"r2\" : best_model [ f \"mean_ { which } _r2\" ], \"r2_err\" : best_model [ f \"std_ { which } _r2\" ] / sqrt ( nfolds ), \"rmse\" : - best_model [ f \"mean_ { which } _neg_root_mean_squared_error\" ], \"rmse_err\" : best_model [ f \"std_ { which } _neg_root_mean_squared_error\" ] / sqrt ( nfolds ), # noqa W503 }","title":"get_metrics()"},{"location":"ref/ml/evaluate/#thermo.stages.evaluate_model.plot_error_distribution","text":"plot_error_distribution ( model : RegressorMixin , dataf : pd . DataFrame , target : str , figpath : Path ) -> None Creates the scatter plot showing the relationship between the true and predicted values. Parameters: Name Type Description Default model RegressorMixin Fitted regression model. required dataf DataFrame training set. required target str Name of the target column. required figpath Path Filepath to save the plot. required Source code in thermo/stages/evaluate_model.py 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 def plot_error_distribution ( model : RegressorMixin , dataf : pd . DataFrame , target : str , figpath : Path ) -> None : \"\"\" Creates the scatter plot showing the relationship between the true and predicted values. Args: model: Fitted regression model. dataf: training set. target: Name of the target column. figpath: Filepath to save the plot. \"\"\" y_true = dataf [ target ] X = dataf . drop ( columns = target ) y_pred = model . predict ( X ) rmse = np . sqrt (( y_true - y_pred ) . pow ( 2 ) . mean ()) x = np . linspace ( y_pred . min (), y_pred . max (), 100 ) fig = sns . jointplot ( x = y_pred , y = y_true , alpha = 0.3 ) fig . ax_joint . plot ( x , x , \"k-\" , alpha = 0.5 ) fig . ax_joint . plot ( x , x + rmse , \"k--\" , alpha = 0.5 ) fig . ax_joint . plot ( x , x - rmse , \"k--\" , alpha = 0.5 ) fig . ax_joint . set_xlabel ( \"prediction (kWh)\" ) fig . ax_joint . set_ylabel ( \"consumption (kWh)\" ) fig . savefig ( figpath )","title":"plot_error_distribution()"},{"location":"ref/ml/evaluate/#thermo.stages.evaluate_model.plot_gridsearch","text":"plot_gridsearch ( dataf : pd . DataFrame , nfolds : int , figpath : Path ) -> None Plots the results of the grid search for the L2 regularization. Parameters: Name Type Description Default dataf DataFrame Grid search results. required nfolds int Number of cross-validation folds in dataf. required figpath Path Filepath to save the plot. required Source code in thermo/stages/evaluate_model.py 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 def plot_gridsearch ( dataf : pd . DataFrame , nfolds : int , figpath : Path ) -> None : \"\"\"Plots the results of the grid search for the L2 regularization. Args: dataf: Grid search results. nfolds: Number of cross-validation folds in dataf. figpath: Filepath to save the plot. \"\"\" x = dataf [ \"param_regression__alpha\" ] y = dataf [ \"mean_test_r2\" ] y_err = dataf [ \"std_test_r2\" ] / sqrt ( nfolds ) plt . errorbar ( x , y , y_err ) plt . xscale ( \"log\" ) plt . ylabel ( \"r2 score\" ) plt . xlabel ( \"L2 regularization\" ) plt . title ( \"Grid search on the test set\" ) plt . savefig ( figpath )","title":"plot_gridsearch()"},{"location":"ref/ml/get_data/","text":"get_data.py This script takes data from different data sources, stored as csv files under assets/ , selects the relevant subset of data. RawDataFile dataclass Represents a raw data file with the instructions for parsing it from_csv from_csv ( file_path : Path , municipality : str , year : int ) -> pd . DataFrame Reads data from a CSV file and selects the data for a specific municipality and year. Parameters: Name Type Description Default file_path Path The path to the CSV file. required municipality str The name of the municipality to filter the data for. required year int The target year to keep in the data. required Returns: Type Description DataFrame The filtered dataset. Source code in thermo/stages/get_data.py 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 def from_csv ( file_path : Path , municipality : str , year : int ) -> pd . DataFrame : \"\"\" Reads data from a CSV file and selects the data for a specific municipality and year. Args: file_path: The path to the CSV file. municipality: The name of the municipality to filter the data for. year: The target year to keep in the data. Returns: The filtered dataset. \"\"\" logger . info ( f \"Loading data from file { file_path . name } \" ) # Read DataFrame and keep only info for correct municipality dataf = pd . read_csv ( file_path , engine = \"pyarrow\" ) . loc [ lambda x : x [ \"MUNICIPALITY\" ] . eq ( municipality ) ] DATECOL = \"DATE\" if \"DATE\" in dataf . columns else \"DATO\" LOCATIONCOLS = [ column for column in dataf . columns if column . startswith ( \"MUNICIPALITY\" ) or column . startswith ( \"SCHOOL\" ) ] # Create a timestamp from date and time, keep only the target year dataf = ( dataf . assign ( TIMESTAMP = lambda x : pd . to_datetime ( np . vectorize ( datetime . combine )( x [ DATECOL ], x [ \"TIME\" ]) ) ) . drop ( columns = [ DATECOL , \"TIME\" ] + LOCATIONCOLS ) . loc [ lambda x : x [ \"TIMESTAMP\" ] . dt . year . eq ( year )] ) return dataf get_data get_data ( building_name : str , municipality : str , year : int , files : list [ dict [ str , Any ]]) -> pd . DataFrame Gets data for a specific building, municipality, and year from different sources and outputs it as a single DataFrame. Parameters: Name Type Description Default building_name str The name of the building. required municipality str The name of the municipality. required year int The target year. required files list [ dict [ str , Any ]] List of file information and processing instructions. required Returns: Type Description DataFrame pd.DataFrame: The merged DataFrame containing the data. Source code in thermo/stages/get_data.py 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 def get_data ( building_name : str , municipality : str , year : int , files : list [ dict [ str , Any ]] ) -> pd . DataFrame : \"\"\" Gets data for a specific building, municipality, and year from different sources and outputs it as a single DataFrame. Args: building_name: The name of the building. municipality: The name of the municipality. year: The target year. files: List of file information and processing instructions. Returns: pd.DataFrame: The merged DataFrame containing the data. \"\"\" logger . info ( f \"Getting data for building { building_name } \" ) logger . debug ( f \"Data for municipality { municipality } on year { year } .\" ) dataf = pd . DataFrame ( index = pd . date_range ( f \" { year } -01-01\" , f \" { year } -12-31\" , freq = \"H\" ) ) for fileinfo in map ( lambda x : RawDataFile ( ** x ), files ): dataf = dataf . join ( how = \"inner\" , other = ( from_csv ( file_path = WORKDIR / fileinfo . file_path , municipality = municipality , year = year , ) . pipe ( select_data , fileinfo . name , ** fileinfo . parse_params ) ), ) return dataf select_bookings_data select_bookings_data ( dataf : pd . DataFrame , ** parse_params : dict [ str , Any ]) -> pd . DataFrame Selects data from the input bookings DataFrame based on specified parameters. It can drop rooms that have never been dropped from the input DataFrame. It aggregates bookings for the same room and timestamp using one of the aggregation methods and sets \"TIMESTAMP\" as index. Parameters: Name Type Description Default dataf DataFrame The input data. required **parse_params dict [ str , Any ] Additional parameters for data parsing. {} Returns: Type Description DataFrame The selected bookings data DataFrame. Source code in thermo/stages/get_data.py 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 def select_bookings_data ( dataf : pd . DataFrame , ** parse_params : dict [ str , Any ] ) -> pd . DataFrame : \"\"\" Selects data from the input bookings DataFrame based on specified parameters. It can drop rooms that have never been dropped from the input DataFrame. It aggregates bookings for the same room and timestamp using one of the aggregation methods and sets \"TIMESTAMP\" as index. Args: dataf: The input data. **parse_params: Additional parameters for data parsing. Returns: The selected bookings data DataFrame. \"\"\" if parse_params . get ( \"drop_empty_rooms\" , False ): non_empty_rooms = ( dataf . groupby ( \"ROOM_ID\" )[ \"BOOKED\" ] . sum () . loc [ lambda x : x . gt ( 0 )] . index . to_list () ) dataf = dataf . loc [ lambda x : x [ \"ROOM_ID\" ] . isin ( non_empty_rooms )] match parse_params . get ( \"aggregation_method\" , \"binary\" ): case \"binary\" : dataf = dataf . pipe ( binary_aggregate_bookings ) case \"fractional\" : dataf = dataf . pipe ( fractional_aggregate_bookings ) case other : raise NotImplementedError ( f \"Aggregation method { other } .\" ) return dataf . pivot ( index = \"TIMESTAMP\" , columns = \"ROOM_ID\" , values = \"BOOKED\" ) . rename ( columns = lambda name : name + \"_booked\" ) select_data select_data ( dataf : pd . DataFrame , name : str , ** parse_params : dict [ str , Any ]) -> pd . DataFrame Selects and cleans a specific dataset based on the type of data (i.e. energy, bookings) and parsing parameters. Parameters: Name Type Description Default dataf DataFrame The input data. required name str The name of the kind of data (i.e. energy, bookings) required **parse_params dict [ str , Any ] Additional parameters for data parsing. {} Returns: Type Description DataFrame The selected and cleaned DataFrame. Raises: Type Description NotImplementedError If a handler for the given file name is not implemented. Source code in thermo/stages/get_data.py 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 def select_data ( dataf : pd . DataFrame , name : str , ** parse_params : dict [ str , Any ] ) -> pd . DataFrame : \"\"\"Selects and cleans a specific dataset based on the type of data (i.e. energy, bookings) and parsing parameters. Args: dataf: The input data. name: The name of the kind of data (i.e. energy, bookings) **parse_params: Additional parameters for data parsing. Returns: The selected and cleaned DataFrame. Raises: NotImplementedError: If a handler for the given file name is not implemented. \"\"\" logger . debug ( f \"Select and transform { name } data\" ) match name : case \"energy\" : return select_energy_data ( dataf , ** parse_params ) case \"bookings\" : return select_bookings_data ( dataf , ** parse_params ) case _ : raise NotImplementedError ( f \"Handler for file name { name } not implemented\" ) select_energy_data select_energy_data ( dataf : pd . DataFrame , ** parse_params : dict [ str , Any ]) -> pd . DataFrame Selects data from the input energy DataFrame based on specified parameters; as for example measure points or measure types (i.e. electricity). Note this flexibility is needed since \"electricity\" can be spelled in different ways for different schools. Parameters: Name Type Description Default dataf DataFrame The input data. required **parse_params dict [ str , Any ] Additional parameters for data parsing. {} Returns: Type Description DataFrame The clean energy data DataFrame with \"TIMESTAMP\" as index. Raises: Type Description NotImplementedError If handling for more than one measure point or type Source code in thermo/stages/get_data.py 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 def select_energy_data ( dataf : pd . DataFrame , ** parse_params : dict [ str , Any ] ) -> pd . DataFrame : \"\"\" Selects data from the input energy DataFrame based on specified parameters; as for example measure points or measure types (i.e. electricity). Note this flexibility is needed since \"electricity\" can be spelled in different ways for different schools. Args: dataf: The input data. **parse_params: Additional parameters for data parsing. Returns: The clean energy data DataFrame with \"TIMESTAMP\" as index. Raises: NotImplementedError: If handling for more than one measure point or type is not implemented. \"\"\" measure_points = parse_params . get ( \"measure_points\" , dataf [ \"MEASURE_POINT\" ] . unique ()) measure_types = parse_params . get ( \"measure_types\" , dataf [ \"MEASURE_TYPE\" ] . unique ()) if len ( measure_points ) != 1 or len ( measure_types ) != 1 : raise NotImplementedError ( \"Handling for more than one measure point or type.\" ) return ( dataf . loc [ lambda x : x [ \"MEASURE_POINT\" ] . isin ( measure_points )] . loc [ lambda x : x [ \"MEASURE_TYPE\" ] . isin ( measure_types )] . set_index ( \"TIMESTAMP\" ) . rename ( columns = { \"VALUE\" : \"electricity\" })[[ \"electricity\" ]] )","title":"get_data.py"},{"location":"ref/ml/get_data/#get_datapy","text":"This script takes data from different data sources, stored as csv files under assets/ , selects the relevant subset of data.","title":"get_data.py"},{"location":"ref/ml/get_data/#thermo.stages.get_data.RawDataFile","text":"Represents a raw data file with the instructions for parsing it","title":"RawDataFile"},{"location":"ref/ml/get_data/#thermo.stages.get_data.from_csv","text":"from_csv ( file_path : Path , municipality : str , year : int ) -> pd . DataFrame Reads data from a CSV file and selects the data for a specific municipality and year. Parameters: Name Type Description Default file_path Path The path to the CSV file. required municipality str The name of the municipality to filter the data for. required year int The target year to keep in the data. required Returns: Type Description DataFrame The filtered dataset. Source code in thermo/stages/get_data.py 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 def from_csv ( file_path : Path , municipality : str , year : int ) -> pd . DataFrame : \"\"\" Reads data from a CSV file and selects the data for a specific municipality and year. Args: file_path: The path to the CSV file. municipality: The name of the municipality to filter the data for. year: The target year to keep in the data. Returns: The filtered dataset. \"\"\" logger . info ( f \"Loading data from file { file_path . name } \" ) # Read DataFrame and keep only info for correct municipality dataf = pd . read_csv ( file_path , engine = \"pyarrow\" ) . loc [ lambda x : x [ \"MUNICIPALITY\" ] . eq ( municipality ) ] DATECOL = \"DATE\" if \"DATE\" in dataf . columns else \"DATO\" LOCATIONCOLS = [ column for column in dataf . columns if column . startswith ( \"MUNICIPALITY\" ) or column . startswith ( \"SCHOOL\" ) ] # Create a timestamp from date and time, keep only the target year dataf = ( dataf . assign ( TIMESTAMP = lambda x : pd . to_datetime ( np . vectorize ( datetime . combine )( x [ DATECOL ], x [ \"TIME\" ]) ) ) . drop ( columns = [ DATECOL , \"TIME\" ] + LOCATIONCOLS ) . loc [ lambda x : x [ \"TIMESTAMP\" ] . dt . year . eq ( year )] ) return dataf","title":"from_csv()"},{"location":"ref/ml/get_data/#thermo.stages.get_data.get_data","text":"get_data ( building_name : str , municipality : str , year : int , files : list [ dict [ str , Any ]]) -> pd . DataFrame Gets data for a specific building, municipality, and year from different sources and outputs it as a single DataFrame. Parameters: Name Type Description Default building_name str The name of the building. required municipality str The name of the municipality. required year int The target year. required files list [ dict [ str , Any ]] List of file information and processing instructions. required Returns: Type Description DataFrame pd.DataFrame: The merged DataFrame containing the data. Source code in thermo/stages/get_data.py 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 def get_data ( building_name : str , municipality : str , year : int , files : list [ dict [ str , Any ]] ) -> pd . DataFrame : \"\"\" Gets data for a specific building, municipality, and year from different sources and outputs it as a single DataFrame. Args: building_name: The name of the building. municipality: The name of the municipality. year: The target year. files: List of file information and processing instructions. Returns: pd.DataFrame: The merged DataFrame containing the data. \"\"\" logger . info ( f \"Getting data for building { building_name } \" ) logger . debug ( f \"Data for municipality { municipality } on year { year } .\" ) dataf = pd . DataFrame ( index = pd . date_range ( f \" { year } -01-01\" , f \" { year } -12-31\" , freq = \"H\" ) ) for fileinfo in map ( lambda x : RawDataFile ( ** x ), files ): dataf = dataf . join ( how = \"inner\" , other = ( from_csv ( file_path = WORKDIR / fileinfo . file_path , municipality = municipality , year = year , ) . pipe ( select_data , fileinfo . name , ** fileinfo . parse_params ) ), ) return dataf","title":"get_data()"},{"location":"ref/ml/get_data/#thermo.stages.get_data.select_bookings_data","text":"select_bookings_data ( dataf : pd . DataFrame , ** parse_params : dict [ str , Any ]) -> pd . DataFrame Selects data from the input bookings DataFrame based on specified parameters. It can drop rooms that have never been dropped from the input DataFrame. It aggregates bookings for the same room and timestamp using one of the aggregation methods and sets \"TIMESTAMP\" as index. Parameters: Name Type Description Default dataf DataFrame The input data. required **parse_params dict [ str , Any ] Additional parameters for data parsing. {} Returns: Type Description DataFrame The selected bookings data DataFrame. Source code in thermo/stages/get_data.py 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 def select_bookings_data ( dataf : pd . DataFrame , ** parse_params : dict [ str , Any ] ) -> pd . DataFrame : \"\"\" Selects data from the input bookings DataFrame based on specified parameters. It can drop rooms that have never been dropped from the input DataFrame. It aggregates bookings for the same room and timestamp using one of the aggregation methods and sets \"TIMESTAMP\" as index. Args: dataf: The input data. **parse_params: Additional parameters for data parsing. Returns: The selected bookings data DataFrame. \"\"\" if parse_params . get ( \"drop_empty_rooms\" , False ): non_empty_rooms = ( dataf . groupby ( \"ROOM_ID\" )[ \"BOOKED\" ] . sum () . loc [ lambda x : x . gt ( 0 )] . index . to_list () ) dataf = dataf . loc [ lambda x : x [ \"ROOM_ID\" ] . isin ( non_empty_rooms )] match parse_params . get ( \"aggregation_method\" , \"binary\" ): case \"binary\" : dataf = dataf . pipe ( binary_aggregate_bookings ) case \"fractional\" : dataf = dataf . pipe ( fractional_aggregate_bookings ) case other : raise NotImplementedError ( f \"Aggregation method { other } .\" ) return dataf . pivot ( index = \"TIMESTAMP\" , columns = \"ROOM_ID\" , values = \"BOOKED\" ) . rename ( columns = lambda name : name + \"_booked\" )","title":"select_bookings_data()"},{"location":"ref/ml/get_data/#thermo.stages.get_data.select_data","text":"select_data ( dataf : pd . DataFrame , name : str , ** parse_params : dict [ str , Any ]) -> pd . DataFrame Selects and cleans a specific dataset based on the type of data (i.e. energy, bookings) and parsing parameters. Parameters: Name Type Description Default dataf DataFrame The input data. required name str The name of the kind of data (i.e. energy, bookings) required **parse_params dict [ str , Any ] Additional parameters for data parsing. {} Returns: Type Description DataFrame The selected and cleaned DataFrame. Raises: Type Description NotImplementedError If a handler for the given file name is not implemented. Source code in thermo/stages/get_data.py 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 def select_data ( dataf : pd . DataFrame , name : str , ** parse_params : dict [ str , Any ] ) -> pd . DataFrame : \"\"\"Selects and cleans a specific dataset based on the type of data (i.e. energy, bookings) and parsing parameters. Args: dataf: The input data. name: The name of the kind of data (i.e. energy, bookings) **parse_params: Additional parameters for data parsing. Returns: The selected and cleaned DataFrame. Raises: NotImplementedError: If a handler for the given file name is not implemented. \"\"\" logger . debug ( f \"Select and transform { name } data\" ) match name : case \"energy\" : return select_energy_data ( dataf , ** parse_params ) case \"bookings\" : return select_bookings_data ( dataf , ** parse_params ) case _ : raise NotImplementedError ( f \"Handler for file name { name } not implemented\" )","title":"select_data()"},{"location":"ref/ml/get_data/#thermo.stages.get_data.select_energy_data","text":"select_energy_data ( dataf : pd . DataFrame , ** parse_params : dict [ str , Any ]) -> pd . DataFrame Selects data from the input energy DataFrame based on specified parameters; as for example measure points or measure types (i.e. electricity). Note this flexibility is needed since \"electricity\" can be spelled in different ways for different schools. Parameters: Name Type Description Default dataf DataFrame The input data. required **parse_params dict [ str , Any ] Additional parameters for data parsing. {} Returns: Type Description DataFrame The clean energy data DataFrame with \"TIMESTAMP\" as index. Raises: Type Description NotImplementedError If handling for more than one measure point or type Source code in thermo/stages/get_data.py 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 def select_energy_data ( dataf : pd . DataFrame , ** parse_params : dict [ str , Any ] ) -> pd . DataFrame : \"\"\" Selects data from the input energy DataFrame based on specified parameters; as for example measure points or measure types (i.e. electricity). Note this flexibility is needed since \"electricity\" can be spelled in different ways for different schools. Args: dataf: The input data. **parse_params: Additional parameters for data parsing. Returns: The clean energy data DataFrame with \"TIMESTAMP\" as index. Raises: NotImplementedError: If handling for more than one measure point or type is not implemented. \"\"\" measure_points = parse_params . get ( \"measure_points\" , dataf [ \"MEASURE_POINT\" ] . unique ()) measure_types = parse_params . get ( \"measure_types\" , dataf [ \"MEASURE_TYPE\" ] . unique ()) if len ( measure_points ) != 1 or len ( measure_types ) != 1 : raise NotImplementedError ( \"Handling for more than one measure point or type.\" ) return ( dataf . loc [ lambda x : x [ \"MEASURE_POINT\" ] . isin ( measure_points )] . loc [ lambda x : x [ \"MEASURE_TYPE\" ] . isin ( measure_types )] . set_index ( \"TIMESTAMP\" ) . rename ( columns = { \"VALUE\" : \"electricity\" })[[ \"electricity\" ]] )","title":"select_energy_data()"},{"location":"ref/ml/preprocessing/","text":"preprocessing.py This script takes care of the feature engineering: it produces the insights we know are there so they can be fed to the machine learning algorithm in the next step. It takes in the raw bookings and does two main tasks: - Drops data that is not interesting - Feature engineering: simulates the ventilation system. drop_nights_and_school drop_nights_and_school ( dataf : pd . DataFrame , drop : bool = True ) -> pd . DataFrame Drops nights and school hours from the DataFrame. Parameters: Name Type Description Default dataf DataFrame The input DataFrame. required drop bool Indicates whether to drop nights and school days. If False, no data is dropped. Defaults to True. True Returns: Type Description DataFrame The processed DataFrame. Source code in thermo/stages/preprocessing.py 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 @log_transformation def drop_nights_and_school ( dataf : pd . DataFrame , drop : bool = True ) -> pd . DataFrame : \"\"\"Drops nights and school hours from the DataFrame. Args: dataf: The input DataFrame. drop: Indicates whether to drop nights and school days. If False, no data is dropped. Defaults to True. Returns: The processed DataFrame. \"\"\" if not drop : return dataf v_schoolday = np . vectorize ( is_schoolday ) schoolday = v_schoolday ( dataf . index . date ) # type: ignore[attr-defined] hour = dataf . index . hour # type: ignore[attr-defined] return dataf . loc [ ( schoolday & ( hour >= WEEKDAY_HOUR_START )) | ( ~ schoolday & ( hour >= WEEKEND_HOUR_START )) # noqa W503 ] drop_unfrequent_rooms drop_unfrequent_rooms ( dataf : pd . DataFrame , threshold : int | None ) -> pd . DataFrame Drops the columns for rooms with low booking frequency from the DataFrame. Parameters: Name Type Description Default dataf DataFrame The input DataFrame. required threshold int | None Rooms with less bookings than this threshold will be dropped. If None, no rooms are dropped. required Returns: Type Description DataFrame The DataFrame with the columns with infrequent rooms dropped. Source code in thermo/stages/preprocessing.py 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 @log_transformation def drop_unfrequent_rooms ( dataf : pd . DataFrame , threshold : int | None ) -> pd . DataFrame : \"\"\" Drops the columns for rooms with low booking frequency from the DataFrame. Args: dataf: The input DataFrame. threshold: Rooms with less bookings than this threshold will be dropped. If None, no rooms are dropped. Returns: The DataFrame with the columns with infrequent rooms dropped. \"\"\" if not threshold : return dataf room_columns = [ col for col in dataf . columns if col . endswith ( \"booked\" )] to_drop = ( dataf [ room_columns ] . sum ( axis = 0 ) . loc [ lambda x : x . lt ( threshold )] . index . to_list () ) return dataf . drop ( columns = to_drop ) drop_unused_days drop_unused_days ( dataf : pd . DataFrame ) -> pd . DataFrame Drops the rows corresponding to days where no room was used from the DataFrame. Parameters: Name Type Description Default dataf DataFrame The input DataFrame. required Returns: Type Description DataFrame The DataFrame with the days where no room was used dropped. Source code in thermo/stages/preprocessing.py 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 @log_transformation def drop_unused_days ( dataf : pd . DataFrame ) -> pd . DataFrame : \"\"\" Drops the rows corresponding to days where no room was used from the DataFrame. Args: dataf: The input DataFrame. Returns: The DataFrame with the days where no room was used dropped. \"\"\" room_columns = [ col for col in dataf . columns if col . endswith ( \"booked\" )] is_used = np . vectorize ( dataf [ room_columns ] . groupby ([ dataf . index . date ]) # type: ignore[attr-defined] . sum () . sum ( axis = 1 ) . astype ( bool ) . to_dict () . __getitem__ ) return dataf . loc [ lambda x : is_used ( x . index . date )] # type: ignore[attr-defined] log_transformation log_transformation ( func : Transformation ) -> Transformation Time logger for preprocessing transformations Source code in thermo/stages/preprocessing.py 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 def log_transformation ( func : Transformation ) -> Transformation : \"\"\" Time logger for preprocessing transformations \"\"\" @wraps ( func ) def wrapper ( dataf : pd . DataFrame , * args , ** kwargs ) -> pd . DataFrame : params = \", \" . join ( f \" { key } = { value } \" for key , value in kwargs . items ()) logger . info ( f \" { func . __name__ } running \\t parameters: { params } .\" ) tic = time . perf_counter () result = func ( dataf , * args , ** kwargs ) time_taken = time . perf_counter () - tic logger . info ( f \" { func . __name__ } completed \\t shape { result . shape } \" f \" \\t time { time_taken : .3f } s\" ) if not result . shape [ 0 ]: logger . error ( f \" { func . __name__ } emptied the DataFrame\" ) return result return wrapper mock_ventilation mock_ventilation ( dataf : pd . DataFrame , params : dict [ str , Any ] | None ) -> pd . DataFrame Mocks ventilation data based on booking information. params = {is_on:True} results in one hot encoding of whether the ventilation is on, and {is_day:True} results in a distinction between if the room was booked or it wasn't but the ventilation is in day mode. Parameters: Name Type Description Default dataf DataFrame The input DataFrame. required params dict [ str , Any ] | None Parameters for ventilation mocking. If None, no mocking is performed. required Returns: Type Description DataFrame The DataFrame with mocked ventilation data. Source code in thermo/stages/preprocessing.py 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 @log_transformation def mock_ventilation ( dataf : pd . DataFrame , params : dict [ str , Any ] | None ) -> pd . DataFrame : \"\"\"Mocks ventilation data based on booking information. params = {is_on:True} results in one hot encoding of whether the ventilation is on, and {is_day:True} results in a distinction between if the room was booked or it wasn't but the ventilation is in day mode. Args: dataf: The input DataFrame. params: Parameters for ventilation mocking. If None, no mocking is performed. Returns: The DataFrame with mocked ventilation data. \"\"\" # If there are no parameters, do nothing if not params : return dataf # Extract flags from params is_on = params . get ( \"is_on\" , False ) is_day = params . get ( \"is_day\" , not is_on ) # Deal with corner cases if not is_on and not is_day : return dataf elif is_on and is_day : raise ValueError ( \"Both is_day and is_on cannot be True at the same time.\" ) # Get room names room_columns = [ col for col in dataf . columns if col . endswith ( \"booked\" )] bookings = dataf [ room_columns ] . copy () ventilation = ( bookings . groupby ([ bookings . index . date ]) # type: ignore[attr-defined] . apply ( lambda x : x . iloc [:: - 1 , :] . cummax () . iloc [:: - 1 , :]) . reset_index ( level = 0 ) . drop ( columns = \"level_0\" ) ) # Add is_day column per room if is_day : ventilation = dataf . join ( how = \"inner\" , other = ( ventilation - bookings ) . rename ( columns = { col : col . split ( \"_booked\" )[ 0 ] + \"_day\" for col in room_columns } ), ) return ventilation preprocess preprocess ( dataf : pd . DataFrame , params : dict [ str , Any ]) -> pd . DataFrame Preprocesses the data based on the given parameters. Parameters: Name Type Description Default dataf DataFrame The input DataFrame. required params dict [ str , Any ] Parameters for data preprocessing. required Returns: Type Description DataFrame pd.DataFrame: The preprocessed DataFrame. Source code in thermo/stages/preprocessing.py 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 def preprocess ( dataf : pd . DataFrame , params : dict [ str , Any ]) -> pd . DataFrame : \"\"\" Preprocesses the data based on the given parameters. Args: dataf: The input DataFrame. params: Parameters for data preprocessing. Returns: pd.DataFrame: The preprocessed DataFrame. \"\"\" return ( dataf . pipe ( drop_unused_days ) . pipe ( drop_unfrequent_rooms , threshold = params . get ( \"booking_hours_threshold\" )) . pipe ( drop_nights_and_school , drop = params . get ( \"drop_nights_and_school_hours\" , False ), ) . pipe ( mock_ventilation , params = params . get ( \"ventilation\" )) )","title":"preprocessing.py"},{"location":"ref/ml/preprocessing/#preprocessingpy","text":"This script takes care of the feature engineering: it produces the insights we know are there so they can be fed to the machine learning algorithm in the next step. It takes in the raw bookings and does two main tasks: - Drops data that is not interesting - Feature engineering: simulates the ventilation system.","title":"preprocessing.py"},{"location":"ref/ml/preprocessing/#thermo.stages.preprocessing.drop_nights_and_school","text":"drop_nights_and_school ( dataf : pd . DataFrame , drop : bool = True ) -> pd . DataFrame Drops nights and school hours from the DataFrame. Parameters: Name Type Description Default dataf DataFrame The input DataFrame. required drop bool Indicates whether to drop nights and school days. If False, no data is dropped. Defaults to True. True Returns: Type Description DataFrame The processed DataFrame. Source code in thermo/stages/preprocessing.py 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 @log_transformation def drop_nights_and_school ( dataf : pd . DataFrame , drop : bool = True ) -> pd . DataFrame : \"\"\"Drops nights and school hours from the DataFrame. Args: dataf: The input DataFrame. drop: Indicates whether to drop nights and school days. If False, no data is dropped. Defaults to True. Returns: The processed DataFrame. \"\"\" if not drop : return dataf v_schoolday = np . vectorize ( is_schoolday ) schoolday = v_schoolday ( dataf . index . date ) # type: ignore[attr-defined] hour = dataf . index . hour # type: ignore[attr-defined] return dataf . loc [ ( schoolday & ( hour >= WEEKDAY_HOUR_START )) | ( ~ schoolday & ( hour >= WEEKEND_HOUR_START )) # noqa W503 ]","title":"drop_nights_and_school()"},{"location":"ref/ml/preprocessing/#thermo.stages.preprocessing.drop_unfrequent_rooms","text":"drop_unfrequent_rooms ( dataf : pd . DataFrame , threshold : int | None ) -> pd . DataFrame Drops the columns for rooms with low booking frequency from the DataFrame. Parameters: Name Type Description Default dataf DataFrame The input DataFrame. required threshold int | None Rooms with less bookings than this threshold will be dropped. If None, no rooms are dropped. required Returns: Type Description DataFrame The DataFrame with the columns with infrequent rooms dropped. Source code in thermo/stages/preprocessing.py 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 @log_transformation def drop_unfrequent_rooms ( dataf : pd . DataFrame , threshold : int | None ) -> pd . DataFrame : \"\"\" Drops the columns for rooms with low booking frequency from the DataFrame. Args: dataf: The input DataFrame. threshold: Rooms with less bookings than this threshold will be dropped. If None, no rooms are dropped. Returns: The DataFrame with the columns with infrequent rooms dropped. \"\"\" if not threshold : return dataf room_columns = [ col for col in dataf . columns if col . endswith ( \"booked\" )] to_drop = ( dataf [ room_columns ] . sum ( axis = 0 ) . loc [ lambda x : x . lt ( threshold )] . index . to_list () ) return dataf . drop ( columns = to_drop )","title":"drop_unfrequent_rooms()"},{"location":"ref/ml/preprocessing/#thermo.stages.preprocessing.drop_unused_days","text":"drop_unused_days ( dataf : pd . DataFrame ) -> pd . DataFrame Drops the rows corresponding to days where no room was used from the DataFrame. Parameters: Name Type Description Default dataf DataFrame The input DataFrame. required Returns: Type Description DataFrame The DataFrame with the days where no room was used dropped. Source code in thermo/stages/preprocessing.py 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 @log_transformation def drop_unused_days ( dataf : pd . DataFrame ) -> pd . DataFrame : \"\"\" Drops the rows corresponding to days where no room was used from the DataFrame. Args: dataf: The input DataFrame. Returns: The DataFrame with the days where no room was used dropped. \"\"\" room_columns = [ col for col in dataf . columns if col . endswith ( \"booked\" )] is_used = np . vectorize ( dataf [ room_columns ] . groupby ([ dataf . index . date ]) # type: ignore[attr-defined] . sum () . sum ( axis = 1 ) . astype ( bool ) . to_dict () . __getitem__ ) return dataf . loc [ lambda x : is_used ( x . index . date )] # type: ignore[attr-defined]","title":"drop_unused_days()"},{"location":"ref/ml/preprocessing/#thermo.stages.preprocessing.log_transformation","text":"log_transformation ( func : Transformation ) -> Transformation Time logger for preprocessing transformations Source code in thermo/stages/preprocessing.py 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 def log_transformation ( func : Transformation ) -> Transformation : \"\"\" Time logger for preprocessing transformations \"\"\" @wraps ( func ) def wrapper ( dataf : pd . DataFrame , * args , ** kwargs ) -> pd . DataFrame : params = \", \" . join ( f \" { key } = { value } \" for key , value in kwargs . items ()) logger . info ( f \" { func . __name__ } running \\t parameters: { params } .\" ) tic = time . perf_counter () result = func ( dataf , * args , ** kwargs ) time_taken = time . perf_counter () - tic logger . info ( f \" { func . __name__ } completed \\t shape { result . shape } \" f \" \\t time { time_taken : .3f } s\" ) if not result . shape [ 0 ]: logger . error ( f \" { func . __name__ } emptied the DataFrame\" ) return result return wrapper","title":"log_transformation()"},{"location":"ref/ml/preprocessing/#thermo.stages.preprocessing.mock_ventilation","text":"mock_ventilation ( dataf : pd . DataFrame , params : dict [ str , Any ] | None ) -> pd . DataFrame Mocks ventilation data based on booking information. params = {is_on:True} results in one hot encoding of whether the ventilation is on, and {is_day:True} results in a distinction between if the room was booked or it wasn't but the ventilation is in day mode. Parameters: Name Type Description Default dataf DataFrame The input DataFrame. required params dict [ str , Any ] | None Parameters for ventilation mocking. If None, no mocking is performed. required Returns: Type Description DataFrame The DataFrame with mocked ventilation data. Source code in thermo/stages/preprocessing.py 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 @log_transformation def mock_ventilation ( dataf : pd . DataFrame , params : dict [ str , Any ] | None ) -> pd . DataFrame : \"\"\"Mocks ventilation data based on booking information. params = {is_on:True} results in one hot encoding of whether the ventilation is on, and {is_day:True} results in a distinction between if the room was booked or it wasn't but the ventilation is in day mode. Args: dataf: The input DataFrame. params: Parameters for ventilation mocking. If None, no mocking is performed. Returns: The DataFrame with mocked ventilation data. \"\"\" # If there are no parameters, do nothing if not params : return dataf # Extract flags from params is_on = params . get ( \"is_on\" , False ) is_day = params . get ( \"is_day\" , not is_on ) # Deal with corner cases if not is_on and not is_day : return dataf elif is_on and is_day : raise ValueError ( \"Both is_day and is_on cannot be True at the same time.\" ) # Get room names room_columns = [ col for col in dataf . columns if col . endswith ( \"booked\" )] bookings = dataf [ room_columns ] . copy () ventilation = ( bookings . groupby ([ bookings . index . date ]) # type: ignore[attr-defined] . apply ( lambda x : x . iloc [:: - 1 , :] . cummax () . iloc [:: - 1 , :]) . reset_index ( level = 0 ) . drop ( columns = \"level_0\" ) ) # Add is_day column per room if is_day : ventilation = dataf . join ( how = \"inner\" , other = ( ventilation - bookings ) . rename ( columns = { col : col . split ( \"_booked\" )[ 0 ] + \"_day\" for col in room_columns } ), ) return ventilation","title":"mock_ventilation()"},{"location":"ref/ml/preprocessing/#thermo.stages.preprocessing.preprocess","text":"preprocess ( dataf : pd . DataFrame , params : dict [ str , Any ]) -> pd . DataFrame Preprocesses the data based on the given parameters. Parameters: Name Type Description Default dataf DataFrame The input DataFrame. required params dict [ str , Any ] Parameters for data preprocessing. required Returns: Type Description DataFrame pd.DataFrame: The preprocessed DataFrame. Source code in thermo/stages/preprocessing.py 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 def preprocess ( dataf : pd . DataFrame , params : dict [ str , Any ]) -> pd . DataFrame : \"\"\" Preprocesses the data based on the given parameters. Args: dataf: The input DataFrame. params: Parameters for data preprocessing. Returns: pd.DataFrame: The preprocessed DataFrame. \"\"\" return ( dataf . pipe ( drop_unused_days ) . pipe ( drop_unfrequent_rooms , threshold = params . get ( \"booking_hours_threshold\" )) . pipe ( drop_nights_and_school , drop = params . get ( \"drop_nights_and_school_hours\" , False ), ) . pipe ( mock_ventilation , params = params . get ( \"ventilation\" )) )","title":"preprocess()"},{"location":"ref/ml/train/","text":"train.py Train a linear regression to extract the cost of booking each room from the data. The model is trained using n-fold cross validation and grid search to decide the value of the L2 regularization that best fits the data. CVResult dataclass Class representing the results of cross-validation. Attributes: Name Type Description name str The name of the model. estimator RegressorMixin The fitted estimator. cv_results DataFrame The cross-validation results. r2_score float The R-squared score. l2_weight float The L2 weight. Methods: Name Description __repr__ Returns a string representation of the CVResult object. get_estimator get_estimator ( name : str ) -> RegressorMixin Returns a sklearn estimator based on the given name. this function is ready to take other linear models but we havent implemented that yet. Parameters: Name Type Description Default name str The name of the estimator. required Returns: Type Description RegressorMixin The corresponding sklearn estimator. Raises: Type Description NameError If the estimator name is not supported. Source code in thermo/stages/train.py 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 def get_estimator ( name : str ) -> RegressorMixin : \"\"\" Returns a sklearn estimator based on the given name. Note: this function is ready to take other linear models but we havent implemented that yet. Args: name: The name of the estimator. Returns: The corresponding sklearn estimator. Raises: NameError: If the estimator name is not supported. \"\"\" match name : case \"RidgeRegression\" : from sklearn.linear_model import Ridge return Ridge ( positive = True ) case _ : raise NameError ( f \"Estimator { name } is not supported\" ) get_feature_targets get_feature_targets ( dataf : pd . DataFrame , target : str ) -> tuple [ pd . DataFrame , pd . Series ] Splits the DataFrame into feature matrix X and target vector y. Parameters: Name Type Description Default dataf DataFrame The input DataFrame. required target str The name of the target column. required Returns: Name Type Description tuple tuple [ DataFrame , Series ] A tuple containing the feature matrix X and the target vector y. Source code in thermo/stages/train.py 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 def get_feature_targets ( dataf : pd . DataFrame , target : str ) -> tuple [ pd . DataFrame , pd . Series ]: \"\"\" Splits the DataFrame into feature matrix X and target vector y. Args: dataf: The input DataFrame. target: The name of the target column. Returns: tuple: A tuple containing the feature matrix X and the target vector y. \"\"\" dataf = dataf . sample ( frac = 1 , random_state = 42 ) # Shuffle y = dataf [ target ] X = dataf . drop ( columns = target ) return X , y train_cv train_cv ( X : pd . DataFrame , y : pd . Series , estimator_name : str = 'RidgeRegression' , cv_folds : int = 5 , alpha_min : float = 0.001 , alpha_max : float = 1 , ** _ ) -> CVResult Trains a ML regression model and finds the optimal L2 regularization coefficient (alpha) using cross-validation. Parameters: Name Type Description Default X DataFrame The feature matrix. required y Series The target vector. required estimator_name str The name of the estimator to use. Defaults to \"RidgeRegression\". 'RidgeRegression' cv_folds int The number of cross-validation folds. Defaults to 5. 5 alpha_min float The minimum alpha value for hyperparameter search. Defaults to 0.001. 0.001 alpha_max float The maximum alpha value for hyperparameter search. Defaults to 1. 1 **_ Optional additional keyword arguments (ignored). {} Returns: Name Type Description CVResult CVResult The cross-validation results. Note The function performs a grid search to find the best hyperparameters for the specified estimator. Source code in thermo/stages/train.py 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 def train_cv ( X : pd . DataFrame , y : pd . Series , estimator_name : str = \"RidgeRegression\" , cv_folds : int = 5 , alpha_min : float = 0.001 , alpha_max : float = 1 , ** _ , ) -> CVResult : \"\"\" Trains a ML regression model and finds the optimal L2 regularization coefficient (alpha) using cross-validation. Args: X: The feature matrix. y: The target vector. estimator_name: The name of the estimator to use. Defaults to \"RidgeRegression\". cv_folds: The number of cross-validation folds. Defaults to 5. alpha_min: The minimum alpha value for hyperparameter search. Defaults to 0.001. alpha_max: The maximum alpha value for hyperparameter search. Defaults to 1. **_: Optional additional keyword arguments (ignored). Returns: CVResult: The cross-validation results. Note: The function performs a grid search to find the best hyperparameters for the specified estimator. \"\"\" # Get hyperparameters range log_min , log_max = tuple ( map ( np . log10 , ( alpha_min , alpha_max ))) alphas = 10 ** np . linspace ( log_min , log_max , 1 + 4 * int ( log_max - log_min ), endpoint = True ) # Find parameters and hyperparameters cv = GridSearchCV ( estimator = Pipeline ( steps = [( \"regression\" , get_estimator ( name = estimator_name ))]), param_grid = { \"regression__alpha\" : alphas }, cv = cv_folds , scoring = [ \"r2\" , \"neg_root_mean_squared_error\" ], refit = \"r2\" , return_train_score = True , n_jobs =- 1 , verbose = 1 , ) cv . fit ( X , y ) return CVResult ( estimator = cv . best_estimator_ , cv_results = pd . DataFrame ( cv . cv_results_ ), r2_score = cv . best_score_ , l2_weight = cv . best_params_ [ \"regression__alpha\" ], name = estimator_name , )","title":"train.py"},{"location":"ref/ml/train/#trainpy","text":"Train a linear regression to extract the cost of booking each room from the data. The model is trained using n-fold cross validation and grid search to decide the value of the L2 regularization that best fits the data.","title":"train.py"},{"location":"ref/ml/train/#thermo.stages.train.CVResult","text":"Class representing the results of cross-validation. Attributes: Name Type Description name str The name of the model. estimator RegressorMixin The fitted estimator. cv_results DataFrame The cross-validation results. r2_score float The R-squared score. l2_weight float The L2 weight. Methods: Name Description __repr__ Returns a string representation of the CVResult object.","title":"CVResult"},{"location":"ref/ml/train/#thermo.stages.train.get_estimator","text":"get_estimator ( name : str ) -> RegressorMixin Returns a sklearn estimator based on the given name. this function is ready to take other linear models but we havent implemented that yet. Parameters: Name Type Description Default name str The name of the estimator. required Returns: Type Description RegressorMixin The corresponding sklearn estimator. Raises: Type Description NameError If the estimator name is not supported. Source code in thermo/stages/train.py 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 def get_estimator ( name : str ) -> RegressorMixin : \"\"\" Returns a sklearn estimator based on the given name. Note: this function is ready to take other linear models but we havent implemented that yet. Args: name: The name of the estimator. Returns: The corresponding sklearn estimator. Raises: NameError: If the estimator name is not supported. \"\"\" match name : case \"RidgeRegression\" : from sklearn.linear_model import Ridge return Ridge ( positive = True ) case _ : raise NameError ( f \"Estimator { name } is not supported\" )","title":"get_estimator()"},{"location":"ref/ml/train/#thermo.stages.train.get_feature_targets","text":"get_feature_targets ( dataf : pd . DataFrame , target : str ) -> tuple [ pd . DataFrame , pd . Series ] Splits the DataFrame into feature matrix X and target vector y. Parameters: Name Type Description Default dataf DataFrame The input DataFrame. required target str The name of the target column. required Returns: Name Type Description tuple tuple [ DataFrame , Series ] A tuple containing the feature matrix X and the target vector y. Source code in thermo/stages/train.py 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 def get_feature_targets ( dataf : pd . DataFrame , target : str ) -> tuple [ pd . DataFrame , pd . Series ]: \"\"\" Splits the DataFrame into feature matrix X and target vector y. Args: dataf: The input DataFrame. target: The name of the target column. Returns: tuple: A tuple containing the feature matrix X and the target vector y. \"\"\" dataf = dataf . sample ( frac = 1 , random_state = 42 ) # Shuffle y = dataf [ target ] X = dataf . drop ( columns = target ) return X , y","title":"get_feature_targets()"},{"location":"ref/ml/train/#thermo.stages.train.train_cv","text":"train_cv ( X : pd . DataFrame , y : pd . Series , estimator_name : str = 'RidgeRegression' , cv_folds : int = 5 , alpha_min : float = 0.001 , alpha_max : float = 1 , ** _ ) -> CVResult Trains a ML regression model and finds the optimal L2 regularization coefficient (alpha) using cross-validation. Parameters: Name Type Description Default X DataFrame The feature matrix. required y Series The target vector. required estimator_name str The name of the estimator to use. Defaults to \"RidgeRegression\". 'RidgeRegression' cv_folds int The number of cross-validation folds. Defaults to 5. 5 alpha_min float The minimum alpha value for hyperparameter search. Defaults to 0.001. 0.001 alpha_max float The maximum alpha value for hyperparameter search. Defaults to 1. 1 **_ Optional additional keyword arguments (ignored). {} Returns: Name Type Description CVResult CVResult The cross-validation results. Note The function performs a grid search to find the best hyperparameters for the specified estimator. Source code in thermo/stages/train.py 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 def train_cv ( X : pd . DataFrame , y : pd . Series , estimator_name : str = \"RidgeRegression\" , cv_folds : int = 5 , alpha_min : float = 0.001 , alpha_max : float = 1 , ** _ , ) -> CVResult : \"\"\" Trains a ML regression model and finds the optimal L2 regularization coefficient (alpha) using cross-validation. Args: X: The feature matrix. y: The target vector. estimator_name: The name of the estimator to use. Defaults to \"RidgeRegression\". cv_folds: The number of cross-validation folds. Defaults to 5. alpha_min: The minimum alpha value for hyperparameter search. Defaults to 0.001. alpha_max: The maximum alpha value for hyperparameter search. Defaults to 1. **_: Optional additional keyword arguments (ignored). Returns: CVResult: The cross-validation results. Note: The function performs a grid search to find the best hyperparameters for the specified estimator. \"\"\" # Get hyperparameters range log_min , log_max = tuple ( map ( np . log10 , ( alpha_min , alpha_max ))) alphas = 10 ** np . linspace ( log_min , log_max , 1 + 4 * int ( log_max - log_min ), endpoint = True ) # Find parameters and hyperparameters cv = GridSearchCV ( estimator = Pipeline ( steps = [( \"regression\" , get_estimator ( name = estimator_name ))]), param_grid = { \"regression__alpha\" : alphas }, cv = cv_folds , scoring = [ \"r2\" , \"neg_root_mean_squared_error\" ], refit = \"r2\" , return_train_score = True , n_jobs =- 1 , verbose = 1 , ) cv . fit ( X , y ) return CVResult ( estimator = cv . best_estimator_ , cv_results = pd . DataFrame ( cv . cv_results_ ), r2_score = cv . best_score_ , l2_weight = cv . best_params_ [ \"regression__alpha\" ], name = estimator_name , )","title":"train_cv()"}]}